{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22964e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 로드 완료: monologg/kobert\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "model_name = \"monologg/kobert\"\n",
    "\n",
    "model = AutoModel.from_pretrained(\"monologg/kobert\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"monologg/kobert\", trust_remote_code=True)\n",
    "\n",
    "\n",
    "print(f\"모델 로드 완료: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "164a549a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰화 결과: ['▁안', '녕', '하세요', '.', '▁한국', '어', '▁B', 'ER', 'T', '▁모델', '을', '▁테스트', '합니다', '.']\n",
      "입력 ID 형태: torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "# 샘플 텍스트\n",
    "text = \"안녕하세요. 한국어 BERT 모델을 테스트합니다.\"\n",
    "\n",
    "# 토큰화\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(f\"토큰화 결과: {tokens}\")\n",
    "\n",
    "# 인코딩 (모델 입력용)\n",
    "encoded = tokenizer.encode_plus(\n",
    "    text,\n",
    "    add_special_tokens=True,\n",
    "    max_length=128,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "print(f\"입력 ID 형태: {encoded['input_ids'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f895d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyewo\\Documents\\ItemBasedCollaborative\\kobert_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class MovieRecommendationSystem:\n",
    "    def __init__(self):\n",
    "        self.kobert_tokenizer = None\n",
    "        self.kobert_model = None\n",
    "        self.tfidf_title = None\n",
    "        self.tfidf_genre = None\n",
    "        self.mlb_genre = None\n",
    "        self.movie_data = None\n",
    "        self.plot_embeddings = None\n",
    "        self.title_matrix = None\n",
    "        self.genre_matrix = None\n",
    "        \n",
    "    def load_kobert_model(self):\n",
    "        \"\"\"KoBERT 모델 로드\"\"\"\n",
    "        print(\"KoBERT 모델 로딩 중...\")\n",
    "        model_name = \"monologg/kobert\"\n",
    "        self.kobert_model = AutoModel.from_pretrained(model_name)\n",
    "        self.kobert_tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "        self.kobert_model.eval()\n",
    "        print(\"KoBERT 모델 로드 완료\")\n",
    "    \n",
    "    def get_kobert_embedding(self, text):\n",
    "        \"\"\"KoBERT를 사용하여 텍스트 임베딩 생성\"\"\"\n",
    "        if not text or pd.isna(text):\n",
    "            return np.zeros(768)  # KoBERT 임베딩 차원\n",
    "        \n",
    "        # 텍스트 길이 제한 (KoBERT 최대 입력 길이 고려)\n",
    "        text = str(text)[:500]\n",
    "        \n",
    "        inputs = self.kobert_tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=512\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.kobert_model(**inputs)\n",
    "            # [CLS] 토큰의 임베딩 사용\n",
    "            embedding = outputs.last_hidden_state[:, 0, :].squeeze().detach().cpu().numpy()\n",
    "        \n",
    "        return embedding\n",
    "    \n",
    "    def prepare_data(self, movies_df):\n",
    "        \"\"\"데이터 전처리 및 특성 추출\"\"\"\n",
    "        print(\"데이터 전처리 중...\")\n",
    "        \n",
    "        # 필수 컬럼 확인\n",
    "        required_columns = ['title', 'overview', 'genres']\n",
    "        for col in required_columns:\n",
    "            if col not in movies_df.columns:\n",
    "                raise ValueError(f\"필수 컬럼 '{col}'이 데이터에 없습니다.\")\n",
    "        \n",
    "        # 결측값 처리\n",
    "        movies_df['title'] = movies_df['title'].fillna('')\n",
    "        movies_df['overview'] = movies_df['overview'].fillna('')\n",
    "        movies_df['genres'] = movies_df['genres'].fillna('')\n",
    "        \n",
    "        self.movie_data = movies_df.copy()\n",
    "        \n",
    "        # 1. 제목 TF-IDF 벡터화\n",
    "        print(\"제목 TF-IDF 벡터화 중...\")\n",
    "        self.tfidf_title = TfidfVectorizer(\n",
    "            max_features=5000,\n",
    "            stop_words=None,\n",
    "            ngram_range=(1, 2),\n",
    "            min_df=2\n",
    "        )\n",
    "        self.title_matrix = self.tfidf_title.fit_transform(movies_df['title'])\n",
    "        \n",
    "        # 2. 장르 처리 (One-hot 인코딩)\n",
    "        print(\"장르 One-hot 인코딩 중...\")\n",
    "        # 장르가 문자열인 경우 리스트로 변환\n",
    "        genre_lists = []\n",
    "        for genres in movies_df['genres']:\n",
    "            if isinstance(genres, str) and genres:\n",
    "                # 장르가 콤마로 구분된 문자열인 경우\n",
    "                genre_list = [g.strip() for g in genres.split(',')]\n",
    "                genre_lists.append(genre_list)\n",
    "            elif isinstance(genres, list):\n",
    "                genre_lists.append(genres)\n",
    "            else:\n",
    "                genre_lists.append([])\n",
    "        \n",
    "        self.mlb_genre = MultiLabelBinarizer()\n",
    "        self.genre_matrix = self.mlb_genre.fit_transform(genre_lists)\n",
    "        \n",
    "        # 3. 줄거리 KoBERT 임베딩\n",
    "        print(\"줄거리 KoBERT 임베딩 생성 중...\")\n",
    "        if self.kobert_model is None:\n",
    "            self.load_kobert_model()\n",
    "        \n",
    "        plot_embeddings = []\n",
    "        for i, overview in enumerate(movies_df['overview']):\n",
    "            if i % 100 == 0:\n",
    "                print(f\"줄거리 임베딩 진행률: {i}/{len(movies_df)}\")\n",
    "            embedding = self.get_kobert_embedding(overview)\n",
    "            plot_embeddings.append(embedding)\n",
    "        \n",
    "        self.plot_embeddings = np.array(plot_embeddings)\n",
    "        print(\"데이터 전처리 완료\")\n",
    "    \n",
    "    def calculate_similarity(self, movie_idx, weights):\n",
    "        \"\"\"특정 영화와 다른 모든 영화 간의 유사도 계산\"\"\"\n",
    "        # weights는 반드시 전달되어야 함 (recommend_movies에서 처리)\n",
    "        \n",
    "        # 1. 줄거리 유사도 (KoBERT 임베딩 기반)\n",
    "        target_plot_embedding = self.plot_embeddings[movie_idx].reshape(1, -1)\n",
    "        plot_similarities = cosine_similarity(target_plot_embedding, self.plot_embeddings)[0]\n",
    "        \n",
    "        # 2. 제목 유사도 (TF-IDF 기반)\n",
    "        target_title_vector = self.title_matrix[movie_idx]\n",
    "        title_similarities = cosine_similarity(target_title_vector, self.title_matrix)[0]\n",
    "        \n",
    "        # 3. 장르 유사도 (One-hot 인코딩 기반)\n",
    "        target_genre_vector = self.genre_matrix[movie_idx].reshape(1, -1)\n",
    "        genre_similarities = cosine_similarity(target_genre_vector, self.genre_matrix)[0]\n",
    "        \n",
    "        # 4. 가중 평균으로 최종 유사도 계산\n",
    "        final_similarities = (\n",
    "            weights['plot'] * plot_similarities +\n",
    "            weights['title'] * title_similarities +\n",
    "            weights['genre'] * genre_similarities\n",
    "        )\n",
    "        \n",
    "        return final_similarities, plot_similarities, title_similarities, genre_similarities\n",
    "    \n",
    "    def recommend_movies(self, movie_title=None, movie_idx=None, top_n=10, weights=None):\n",
    "        \"\"\"영화 추천\"\"\"\n",
    "        \n",
    "        # 기본 가중치 설정\n",
    "        if weights is None:\n",
    "            weights = {'plot': 0.7, 'title': 0.15, 'genre': 0.15}\n",
    "        \n",
    "        if movie_idx is None:\n",
    "            if movie_title is None:\n",
    "                raise ValueError(\"movie_title 또는 movie_idx 중 하나는 제공되어야 합니다.\")\n",
    "            \n",
    "            # 제목으로 인덱스 찾기\n",
    "            matches = self.movie_data[self.movie_data['title'].str.contains(movie_title, case=False, na=False)]\n",
    "            if matches.empty:\n",
    "                print(f\"'{movie_title}'과 일치하는 영화를 찾을 수 없습니다.\")\n",
    "                return None\n",
    "            \n",
    "            movie_idx = matches.index[0]\n",
    "            actual_title = matches.iloc[0]['title']\n",
    "        else:\n",
    "            actual_title = self.movie_data.iloc[movie_idx]['title']\n",
    "        \n",
    "        print(f\"\\n기준 영화: {actual_title}\")\n",
    "        print(f\"장르: {self.movie_data.iloc[movie_idx]['genres']}\")\n",
    "        print(f\"줄거리: {self.movie_data.iloc[movie_idx]['overview'][:200]}...\")\n",
    "        print(f\"사용된 가중치: {weights}\")  # 가중치 출력 추가\n",
    "        \n",
    "        # 유사도 계산 (weights 매개변수 전달)\n",
    "        final_similarities, plot_sim, title_sim, genre_sim = self.calculate_similarity(movie_idx, weights)\n",
    "        \n",
    "        # 자기 자신 제외하고 상위 N개 추천\n",
    "        similar_indices = np.argsort(final_similarities)[::-1][1:top_n+1]\n",
    "        \n",
    "        # 추천 결과 생성\n",
    "        recommendations = []\n",
    "        for idx in similar_indices:\n",
    "            movie_info = {\n",
    "                'title': self.movie_data.iloc[idx]['title'],\n",
    "                'genres': self.movie_data.iloc[idx]['genres'],\n",
    "                'overview': self.movie_data.iloc[idx]['overview'],\n",
    "                'total_similarity': final_similarities[idx],\n",
    "                'plot_similarity': plot_sim[idx],\n",
    "                'title_similarity': title_sim[idx],\n",
    "                'genre_similarity': genre_sim[idx]\n",
    "            }\n",
    "            recommendations.append(movie_info)\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def display_recommendations(self, recommendations):\n",
    "        \"\"\"추천 결과 출력\"\"\"\n",
    "        if not recommendations:\n",
    "            print(\"추천할 영화가 없습니다.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n=== 추천 영화 TOP {len(recommendations)} ===\")\n",
    "        \n",
    "        for i, movie in enumerate(recommendations, 1):\n",
    "            print(f\"\\n{i}. {movie['title']}\")\n",
    "            print(f\"   장르: {movie['genres']}\")\n",
    "            print(f\"   총 유사도: {movie['total_similarity']:.3f}\")\n",
    "            print(f\"   세부 유사도 - 줄거리: {movie['plot_similarity']:.3f}, \"\n",
    "                  f\"제목: {movie['title_similarity']:.3f}, \"\n",
    "                  f\"장르: {movie['genre_similarity']:.3f}\")\n",
    "            print(f\"   줄거리: {movie['overview'][:150]}...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efcc3535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 전처리 중...\n",
      "제목 TF-IDF 벡터화 중...\n",
      "장르 One-hot 인코딩 중...\n",
      "줄거리 KoBERT 임베딩 생성 중...\n",
      "KoBERT 모델 로딩 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyewo\\Documents\\ItemBasedCollaborative\\kobert_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KoBERT 모델 로드 완료\n",
      "줄거리 임베딩 진행률: 0/11\n",
      "데이터 전처리 완료\n",
      "\n",
      "기준 영화: 어벤져스\n",
      "장르: 액션, SF, 어드벤처\n",
      "줄거리: 지구를 위협하는 적으로부터 세상을 구하기 위해 아이언맨, 토르, 캡틴 아메리카 등 슈퍼히어로들이 모인다....\n",
      "사용된 가중치: {'plot': 0.7, 'title': 0.2, 'genre': 0.1}\n",
      "\n",
      "=== 추천 영화 TOP 3 ===\n",
      "\n",
      "1. 가디언즈 오브 갤럭시\n",
      "   장르: SF, 액션, 어드벤처\n",
      "   총 유사도: 0.673\n",
      "   세부 유사도 - 줄거리: 0.819, 제목: 0.000, 장르: 1.000\n",
      "   줄거리: 우주 최강의 악당으로부터 은하계를 지키기 위해 모인 개성 넘치는 히어로들의 이야기....\n",
      "\n",
      "2. 캡틴 아메리카: 시빌 워\n",
      "   장르: 액션, SF, 드라마\n",
      "   총 유사도: 0.642\n",
      "   세부 유사도 - 줄거리: 0.822, 제목: 0.000, 장르: 0.667\n",
      "   줄거리: 초인 등록제를 둘러싸고 슈퍼히어로들이 둘로 나뉘어 대립한다. 아이언맨과 캡틴 아메리카가 이끄는 연합의 충돌....\n",
      "\n",
      "3. 아바타\n",
      "   장르: SF, 액션, 어드벤처\n",
      "   총 유사도: 0.638\n",
      "   세부 유사도 - 줄거리: 0.768, 제목: 0.000, 장르: 1.000\n",
      "   줄거리: 2154년, 지구의 에너지 고갈로 인해 판도라 행성으로 떠난 인간들이 그곳에서 벌이는 전쟁을 그린 SF 영화....\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 사용 예시\n",
    "def create_sample_data():\n",
    "    \"\"\"샘플 데이터 생성\"\"\"\n",
    "    sample_movies = [\n",
    "        {\n",
    "            'title': '기생충',\n",
    "            'overview': '전원 백수로 살 길 막막하지만 사이는 좋은 기택 가족. 장남 기우가 명문대생 친구의 소개로 박 사장 집 가정교사 일을 하게 되면서 운명이 바뀌기 시작한다.',\n",
    "            'genres': '드라마, 스릴러, 코미디'\n",
    "        },\n",
    "        {\n",
    "            'title': '아바타',\n",
    "            'overview': '2154년, 지구의 에너지 고갈로 인해 판도라 행성으로 떠난 인간들이 그곳에서 벌이는 전쟁을 그린 SF 영화.',\n",
    "            'genres': 'SF, 액션, 어드벤처'\n",
    "        },\n",
    "        {\n",
    "            'title': '타이타닉',\n",
    "            'overview': '1912년 침몰한 타이타닉호를 배경으로 한 로맨스 영화. 서로 다른 계층의 잭과 로즈의 사랑 이야기.',\n",
    "            'genres': '로맨스, 드라마'\n",
    "        },\n",
    "        {\n",
    "            'title': '어벤져스',\n",
    "            'overview': '지구를 위협하는 적으로부터 세상을 구하기 위해 아이언맨, 토르, 캡틴 아메리카 등 슈퍼히어로들이 모인다.',\n",
    "            'genres': '액션, SF, 어드벤처'\n",
    "        },\n",
    "        {\n",
    "            'title': '부산행',\n",
    "            'overview': '정체불명의 바이러스가 전국으로 확산되고, KTX를 타고 부산으로 향하는 사람들의 생존 이야기.',\n",
    "            'genres': '액션, 호러, 스릴러'\n",
    "        },\n",
    "        {\n",
    "            'title': '캡틴 아메리카: 시빌 워',\n",
    "            'overview': '초인 등록제를 둘러싸고 슈퍼히어로들이 둘로 나뉘어 대립한다. 아이언맨과 캡틴 아메리카가 이끄는 연합의 충돌.',\n",
    "            'genres': '액션, SF, 드라마'\n",
    "        },\n",
    "        {\n",
    "            'title': '가디언즈 오브 갤럭시',\n",
    "            'overview': '우주 최강의 악당으로부터 은하계를 지키기 위해 모인 개성 넘치는 히어로들의 이야기.',\n",
    "            'genres': 'SF, 액션, 어드벤처'\n",
    "        },\n",
    "        {\n",
    "            'title': '블랙 팬서',\n",
    "            'overview': '와칸다 왕국의 왕이자 히어로 블랙 팬서가 나라를 지키고 지구의 운명을 건 전쟁에 나선다.',\n",
    "            'genres': '액션, SF, 드라마'\n",
    "        },\n",
    "        {\n",
    "            'title': '아바타: 물의 길',\n",
    "            'overview': '판도라 행성의 바다 부족과 함께 가족을 지키기 위한 전쟁이 다시 시작된다.',\n",
    "            'genres': 'SF, 어드벤처, 드라마'\n",
    "        },\n",
    "        {\n",
    "            'title': '인터스텔라',\n",
    "            'overview': '지구의 생존이 위협받는 가운데, 새로운 행성을 찾아 우주를 여행하는 인간들의 이야기.',\n",
    "            'genres': 'SF, 드라마'\n",
    "        },\n",
    "        {\n",
    "            'title': '가타카',\n",
    "            'overview': '유전자 기반 사회에서 한 남자가 우주 비행사의 꿈을 이루기 위해 싸우는 미래 SF 영화.',\n",
    "            'genres': 'SF, 드라마'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    return pd.DataFrame(sample_movies)\n",
    "\n",
    "# 실행 예시\n",
    "if __name__ == \"__main__\":\n",
    "    # 샘플 데이터 생성\n",
    "    movies_df = create_sample_data()\n",
    "    \n",
    "    # 추천 시스템 초기화\n",
    "    recommender = MovieRecommendationSystem()\n",
    "    \n",
    "    # 데이터 전처리\n",
    "    recommender.prepare_data(movies_df)\n",
    "    \n",
    "    # # 영화 추천\n",
    "    # recommendations = recommender.recommend_movies(\n",
    "    #     movie_title='기생충',\n",
    "    #     top_n=3,\n",
    "    #     weights={'plot': 0.7, 'title': 0.15, 'genre': 0.15}\n",
    "    # )\n",
    "    \n",
    "    # # 결과 출력\n",
    "    # recommender.display_recommendations(recommendations)\n",
    "    \n",
    "    # print(\"\\n\" + \"=\"*50)\n",
    "    # print(\"다른 가중치로 추천해보기\")\n",
    "    # print(\"=\"*50)\n",
    "    \n",
    "    # 다른 가중치로 추천\n",
    "    recommendations2 = recommender.recommend_movies(\n",
    "        movie_title='어벤져스',\n",
    "        top_n=3,\n",
    "        weights={'plot': 0.7, 'title': 0.2, 'genre': 0.1}\n",
    "    )\n",
    "    \n",
    "    recommender.display_recommendations(recommendations2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b5f594",
   "metadata": {},
   "outputs": [],
   "source": [
    "   # def get_kobert_embedding(self, text):\n",
    "    #     \"\"\"KoBERT를 사용하여 텍스트 임베딩 생성\"\"\"\n",
    "    #     if not text or pd.isna(text):\n",
    "    #         return np.zeros(768)\n",
    "        \n",
    "    #     # 텍스트 전처리\n",
    "    #     text = self.enhanced_text_preprocessing(text)\n",
    "    #     text = text[:500]  # 길이 제한\n",
    "        \n",
    "    #     inputs = self.kobert_tokenizer(\n",
    "    #         text,\n",
    "    #         return_tensors=\"pt\",\n",
    "    #         truncation=True,\n",
    "    #         padding=True,\n",
    "    #         max_length=512\n",
    "    #     )\n",
    "        \n",
    "    #     with torch.no_grad():\n",
    "    #         outputs = self.kobert_model(**inputs)\n",
    "            \n",
    "    #         # [CLS] 토큰 임베딩\n",
    "    #         cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().detach().cpu().numpy()\n",
    "            \n",
    "    #         # 전체 토큰 평균 임베딩\n",
    "    #         attention_mask = inputs['attention_mask']\n",
    "    #         token_embeddings = outputs.last_hidden_state\n",
    "            \n",
    "    #         mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    #         masked_embeddings = token_embeddings * mask_expanded\n",
    "    #         summed_embeddings = torch.sum(masked_embeddings, 1)\n",
    "    #         summed_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n",
    "    #         mean_embedding = (summed_embeddings / summed_mask).squeeze().detach().cpu().numpy()\n",
    "            \n",
    "    #         # 결합 임베딩\n",
    "    #         combined_embedding = 0.7 * cls_embedding + 0.3 * mean_embedding\n",
    "            \n",
    "    #         # L2 정규화 추가\n",
    "    #         norm = np.linalg.norm(combined_embedding)\n",
    "    #         if norm > 0:\n",
    "    #             combined_embedding = combined_embedding / norm\n",
    "                \n",
    "    #         return combined_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540ab8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyewo\\Documents\\ItemBasedCollaborative\\kobert_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "class ImprovedMovieRecommendationSystem:\n",
    "    def __init__(self):\n",
    "        self.kobert_tokenizer = None\n",
    "        self.kobert_model = None\n",
    "        self.tfidf_title = None\n",
    "        self.tfidf_overview = None\n",
    "        self.tfidf_keywords = None\n",
    "        self.mlb_genre = None\n",
    "        self.movie_data = None\n",
    "        self.plot_embeddings = None\n",
    "        self.title_matrix = None\n",
    "        self.genre_matrix = None\n",
    "        self.keyword_matrix = None\n",
    "        self.overview_matrix = None\n",
    "        \n",
    "    def load_kobert_model(self):\n",
    "        \"\"\"KoBERT 모델 로드\"\"\"\n",
    "        print(\"KoBERT 모델 로딩 중...\")\n",
    "        model_name = \"monologg/kobert\"\n",
    "        self.kobert_model = AutoModel.from_pretrained(model_name)\n",
    "        self.kobert_tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "        self.kobert_model.eval()\n",
    "        print(\"KoBERT 모델 로드 완료\")\n",
    "\n",
    "    def extract_nouns_from_text(text, okt):\n",
    "        \"\"\"텍스트에서 명사 추출\"\"\"\n",
    "        if not text:\n",
    "            return []\n",
    "        \n",
    "        # 명사 추출\n",
    "        nouns = okt.nouns(text)\n",
    "        \n",
    "        # 단어 길이가 1 이하인 것 제거\n",
    "        filtered_nouns = [noun for noun in nouns if len(noun) > 1]\n",
    "        \n",
    "        return filtered_nouns\n",
    "    \n",
    "    def extract_keywords(self, text):\n",
    "        \"\"\"텍스트에서 키워드 추출\"\"\"\n",
    "        if not text or pd.isna(text):\n",
    "            return []\n",
    "        \n",
    "        # 한국어 영화 관련 키워드 패턴\n",
    "        movie_keywords = {\n",
    "             # 장르 관련 (확장)\n",
    "            'action': [\n",
    "                '액션', '전투', '싸움', '전쟁', '격투', '추격', '폭발', '총격',\n",
    "                '무술', '카체이싱', '건파이트', '배틀', '액션스릴러', '느와르',\n",
    "                '스파이', '첩보', '잠입', '미션', '작전', '복수', '정의'\n",
    "            ],\n",
    "            'romance': [\n",
    "                '사랑', '로맨스', '연인', '결혼', '연애', '첫사랑', '이별', '만남',\n",
    "                '멜로', '러브스토리', '운명', '재회', '프로포즈', '웨딩', '데이트',\n",
    "                '썸', '고백', '짝사랑', '원거리', '국제연애', '나이차', '사내연애'\n",
    "            ],\n",
    "            'comedy': [\n",
    "                '코미디', '웃음', '유머', '재미', '개그', '유쾌', '농담',\n",
    "                '개그맨', '상황극', '슬랩스틱', '로맨틱코미디', '패밀리코미디',\n",
    "                '블랙코미디', '풍자', '해학', '익살', '코믹', '유머러스'\n",
    "            ],\n",
    "            'horror': [\n",
    "                '공포', '호러', '무서운', '귀신', '좀비', '괴물', '악령',\n",
    "                '사이코', '살인마', '연쇄살인', '초자연', '오컬트', '엑소시즘',\n",
    "                '저주', '원혼', '귀신', '유령', '무덤', '폐가', '심령'\n",
    "            ],\n",
    "            'thriller': [\n",
    "                '스릴러', '긴장', '추적', '수사', '범죄', '살인', '미스터리',\n",
    "                '서스펜스', '추리', '탐정', '형사', '검찰', '법정', '재판',\n",
    "                '납치', '협박', '음모', '배신', '사기', '해킹', '첩보'\n",
    "            ],\n",
    "            'drama': [\n",
    "                '드라마', '인간', '감동', '눈물', '가족', '인생', '성장',\n",
    "                '휴먼드라마', '가족드라마', '성장드라마', '시대드라마',\n",
    "                '사회드라마', '의료드라마', '법정드라마', '학원드라마'\n",
    "            ],\n",
    "            'SF': [\n",
    "                'SF', '미래', '우주', '로봇', '과학', '기술', '외계', '시간여행',\n",
    "                '사이버펑크', '디스토피아', '유토피아', 'AI', '인공지능',\n",
    "                '가상현실', '바이오', '복제', '돌연변이', '포스트아포칼립스'\n",
    "            ],\n",
    "            'fantasy': [\n",
    "                '판타지', '마법', '신화', '용', '마술', '초자연',\n",
    "                '다크판타지', '어반판타지', '하이판타지', '무협', '환상',\n",
    "                '마법사', '마녀', '요정', '전설', '신화'\n",
    "            ],\n",
    "            \n",
    "            # 세부 장르 추가\n",
    "            'documentary': [\n",
    "                '다큐멘터리', '다큐', '실화', '실제', '기록', '취재',\n",
    "                '사회고발', '환경', '역사', '인물', '음악다큐', '여행다큐'\n",
    "            ],\n",
    "            'animation': [\n",
    "                '애니메이션', '애니', '만화', '3D', '2D', '스톱모션',\n",
    "                '가족애니', '성인애니', 'CGI', '픽사', '디즈니'\n",
    "            ],\n",
    "            'musical': [\n",
    "                '뮤지컬', '음악', '노래', '춤', '공연', '오페라',\n",
    "                '밴드', '가수', '댄스', '음악영화', '콘서트'\n",
    "            ],\n",
    "            'western': [\n",
    "                '서부', '카우보이', '총잡이', '보안관', '무법자',\n",
    "                '황야', '술집', '결투', '정착민'\n",
    "            ],\n",
    "            'sports': [\n",
    "                '스포츠', '운동', '축구', '야구', '농구', '복싱',\n",
    "                '마라톤', '올림픽', '경기', '팀', '코치', '선수'\n",
    "            ],\n",
    "            \n",
    "            # 인물 관련 (확장)\n",
    "            'hero': [\n",
    "                '히어로', '영웅', '주인공', '구원', '슈퍼히어로',\n",
    "                '구세주', '리더', '대장', '캡틴', '왕', '황제', '장군'\n",
    "            ],\n",
    "            'villain': [\n",
    "                '악역', '악당', '범죄자', '적', '보스',\n",
    "                '마피아', '조직', '테러리스트', '독재자', '사이코패스'\n",
    "            ],\n",
    "            'family': [\n",
    "                '아버지', '어머니', '아들', '딸', '형제', '자매',\n",
    "                '할아버지', '할머니', '삼촌', '이모', '고모', '숙부',\n",
    "                '사위', '며느리', '손자', '손녀', '조카', '입양'\n",
    "            ],\n",
    "            'profession': [\n",
    "                '의사', '변호사', '교사', '경찰', '소방관', '군인',\n",
    "                '기자', '작가', '화가', '음악가', '요리사', '사업가',\n",
    "                '정치인', '연예인', '운동선수', '과학자', '엔지니어'\n",
    "            ],\n",
    "            \n",
    "            # 배경 관련 (확장)\n",
    "            'modern': [\n",
    "                '현대', '도시', '서울', '뉴욕', '일상',\n",
    "                '아파트', '오피스', '카페', '클럽', '쇼핑몰',\n",
    "                '지하철', '고속도로', '공항', '호텔'\n",
    "            ],\n",
    "            'historical': [\n",
    "                '역사', '전통', '고대', '중세', '조선',\n",
    "                '임진왜란', '일제강점기', '6.25', '80년대', '90년대',\n",
    "                '궁궐', '한옥', '전쟁', '왕조', '신라', '고구려', '백제'\n",
    "            ],\n",
    "            'future': [\n",
    "                '미래', '2030', '2050', '디스토피아',\n",
    "                '포스트아포칼립스', '사이버펑크', '스페이스오페라'\n",
    "            ],\n",
    "            'space': [\n",
    "                '우주', '행성', '은하', '우주선', '외계',\n",
    "                '화성', '달', '소행성', '블랙홀', '워프'\n",
    "            ],\n",
    "            'school': [\n",
    "                '학교', '대학', '학생', '교실', '캠퍼스',\n",
    "                '초등학교', '중학교', '고등학교', '대학교', '대학원',\n",
    "                '기숙사', '동아리', '학회', '졸업', '입학'\n",
    "            ],\n",
    "            'workplace': [\n",
    "                '회사', '직장', '사무실', '공장', '병원',\n",
    "                '법원', '경찰서', '방송국', '신문사', '은행'\n",
    "            ],\n",
    "            \n",
    "            # 감정/분위기 관련\n",
    "            'emotion': [\n",
    "                '감동', '눈물', '슬픔', '기쁨', '행복', '분노',\n",
    "                '절망', '희망', '사랑', '이별', '그리움', '향수',\n",
    "                '외로움', '고독', '우울', '스트레스'\n",
    "            ],\n",
    "            'mood': [\n",
    "                '다크', '밝은', '유쾌', '우울', '무거운', '가벼운',\n",
    "                '긴장감', '서정적', '잔잔한', '격렬한', '평화로운'\n",
    "            ],\n",
    "            \n",
    "            # 소재/테마 관련\n",
    "            'theme': [\n",
    "                '복수', '정의', '우정', '배신', '희생',\n",
    "                '성장', '자아실현', '꿈', '도전', '극복', '화해',\n",
    "                '갈등', '대립', '협력', '경쟁', '성공', '실패'\n",
    "            ],\n",
    "            'social_issue': [\n",
    "                '사회문제', '부패', '불평등', '차별', '환경',\n",
    "                '정치', '경제', '교육', '의료', '복지',\n",
    "                '성차별', '연령차별', '계층갈등', '지역갈등'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # 키워드 추출\n",
    "        extracted_keywords = []\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        for category, keywords in movie_keywords.items():\n",
    "            for keyword in keywords:\n",
    "                if keyword in text_lower:\n",
    "                    extracted_keywords.append(keyword)\n",
    "        \n",
    "        return extracted_keywords\n",
    "\n",
    "\n",
    "\n",
    "    def get_kobert_embedding(self, text):\n",
    "        \"\"\"KoBERT를 사용하여 텍스트 임베딩 생성\"\"\"\n",
    "        if not text or pd.isna(text):\n",
    "            return np.zeros(768)  # KoBERT 임베딩 차원\n",
    "        \n",
    "        text = self.enhanced_text_preprocessing(text)\n",
    "        \n",
    "        # 텍스트 길이 제한 (KoBERT 최대 입력 길이 고려)\n",
    "        text = str(text)[:500]\n",
    "        \n",
    "        inputs = self.kobert_tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=512\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.kobert_model(**inputs)\n",
    "            # [CLS] 토큰의 임베딩 사용\n",
    "            embedding = outputs.last_hidden_state[:, 0, :].squeeze().detach().cpu().numpy()\n",
    "        \n",
    "        return embedding\n",
    "    \n",
    "    def calculate_genre_similarity_advanced(self, target_genres, candidate_genres):\n",
    "        \"\"\"고급 장르 유사도 계산\"\"\"\n",
    "        # 장르 간 유사도 매트릭스 (실제로는 더 정교하게 구성 가능)\n",
    "        genre_similarity_matrix = {\n",
    "            '액션': {\n",
    "                '모험': 0.8,\n",
    "                'SF': 0.7,\n",
    "                '스릴러': 0.6,\n",
    "                '범죄': 0.5,\n",
    "                '판타지': 0.4,\n",
    "                '전쟁': 0.6,\n",
    "                '서부': 0.5\n",
    "            },\n",
    "            \n",
    "            '모험': {\n",
    "                '액션': 0.8,\n",
    "                '판타지': 0.7,\n",
    "                'SF': 0.6,\n",
    "                '가족': 0.6,\n",
    "                '애니메이션': 0.5,\n",
    "                '역사': 0.4\n",
    "            },\n",
    "            \n",
    "            '애니메이션': {\n",
    "                '가족': 0.8,\n",
    "                '코미디': 0.6,\n",
    "                '판타지': 0.5,\n",
    "                '모험': 0.5,\n",
    "                '로맨스': 0.4,\n",
    "                '드라마': 0.3\n",
    "            },\n",
    "            \n",
    "            '코미디': {\n",
    "                '로맨스': 0.5,\n",
    "                '드라마': 0.4,\n",
    "                '애니메이션': 0.6,\n",
    "                '가족': 0.5,\n",
    "                '음악': 0.3\n",
    "            },\n",
    "            \n",
    "            '범죄': {\n",
    "                '스릴러': 0.8,\n",
    "                '미스터리': 0.7,\n",
    "                '드라마': 0.6,\n",
    "                '액션': 0.5,\n",
    "                '공포': 0.4\n",
    "            },\n",
    "            \n",
    "            '다큐멘터리': {\n",
    "                '역사': 0.6,\n",
    "                '드라마': 0.4,\n",
    "                '음악': 0.3,\n",
    "                '전쟁': 0.3\n",
    "            },\n",
    "            \n",
    "            '드라마': {\n",
    "                '로맨스': 0.7,\n",
    "                '스릴러': 0.5,\n",
    "                '코미디': 0.4,\n",
    "                '범죄': 0.6,\n",
    "                '미스터리': 0.5,\n",
    "                '역사': 0.4,\n",
    "                '다큐멘터리': 0.4,\n",
    "                '가족': 0.5,\n",
    "                '음악': 0.4\n",
    "            },\n",
    "            \n",
    "            '가족': {\n",
    "                '애니메이션': 0.8,\n",
    "                '코미디': 0.5,\n",
    "                '모험': 0.6,\n",
    "                '판타지': 0.5,\n",
    "                '드라마': 0.5,\n",
    "                '로맨스': 0.4\n",
    "            },\n",
    "            \n",
    "            '판타지': {\n",
    "                '모험': 0.7,\n",
    "                'SF': 0.6,\n",
    "                '액션': 0.4,\n",
    "                '애니메이션': 0.5,\n",
    "                '가족': 0.5,\n",
    "                '공포': 0.5\n",
    "            },\n",
    "            \n",
    "            '역사': {\n",
    "                '드라마': 0.4,\n",
    "                '전쟁': 0.8,\n",
    "                '다큐멘터리': 0.6,\n",
    "                '모험': 0.4,\n",
    "                '서부': 0.5\n",
    "            },\n",
    "            \n",
    "            '공포': {\n",
    "                '스릴러': 0.7,\n",
    "                '미스터리': 0.6,\n",
    "                '판타지': 0.5,\n",
    "                'SF': 0.3,\n",
    "                '범죄': 0.4\n",
    "            },\n",
    "            \n",
    "            '음악': {\n",
    "                '드라마': 0.4,\n",
    "                '코미디': 0.3,\n",
    "                '로맨스': 0.5,\n",
    "                '다큐멘터리': 0.3\n",
    "            },\n",
    "            \n",
    "            '미스터리': {\n",
    "                '범죄': 0.7,\n",
    "                '스릴러': 0.8,\n",
    "                '공포': 0.6,\n",
    "                '드라마': 0.5\n",
    "            },\n",
    "            \n",
    "            '로맨스': {\n",
    "                '드라마': 0.7,\n",
    "                '코미디': 0.5,\n",
    "                '음악': 0.5,\n",
    "                '애니메이션': 0.4,\n",
    "                '가족': 0.4\n",
    "            },\n",
    "            \n",
    "            'SF': {\n",
    "                '액션': 0.7,\n",
    "                '모험': 0.6,\n",
    "                '판타지': 0.6,\n",
    "                '스릴러': 0.5,\n",
    "                '공포': 0.3\n",
    "            },\n",
    "            \n",
    "            '스릴러': {\n",
    "                '범죄': 0.8,\n",
    "                '미스터리': 0.8,\n",
    "                '공포': 0.7,\n",
    "                '액션': 0.6,\n",
    "                '드라마': 0.5,\n",
    "                'SF': 0.5\n",
    "            },\n",
    "            \n",
    "            '전쟁': {\n",
    "                '역사': 0.8,\n",
    "                '드라마': 0.6,\n",
    "                '액션': 0.6,\n",
    "                '다큐멘터리': 0.3\n",
    "            },\n",
    "            \n",
    "            '서부': {\n",
    "                '액션': 0.5,\n",
    "                '역사': 0.5,\n",
    "                '드라마': 0.4\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        if not target_genres or not candidate_genres:\n",
    "            return 0.0\n",
    "        \n",
    "        # 직접 매치 점수\n",
    "        direct_match = len(set(target_genres) & set(candidate_genres)) / len(set(target_genres) | set(candidate_genres))\n",
    "        \n",
    "        # 간접 매치 점수\n",
    "        indirect_score = 0\n",
    "        for target_genre in target_genres:\n",
    "            for candidate_genre in candidate_genres:\n",
    "                if target_genre.lower() in genre_similarity_matrix:\n",
    "                    if candidate_genre.lower() in genre_similarity_matrix[target_genre.lower()]:\n",
    "                        indirect_score += genre_similarity_matrix[target_genre.lower()][candidate_genre.lower()]\n",
    "        \n",
    "        indirect_score = indirect_score / (len(target_genres) * len(candidate_genres)) if target_genres and candidate_genres else 0\n",
    "        \n",
    "        return 0.7 * direct_match + 0.3 * indirect_score\n",
    "    \n",
    "    def prepare_data(self, movies_df, force_recompute=False):\n",
    "        \"\"\"데이터 전처리 및 특성 추출\"\"\"\n",
    "        print(\"데이터 전처리 중...\")\n",
    "        \n",
    "        # 필수 컬럼 확인\n",
    "        required_columns = ['title', 'overview', 'genres']\n",
    "        for col in required_columns:\n",
    "            if col not in movies_df.columns:\n",
    "                raise ValueError(f\"필수 컬럼 '{col}'이 데이터에 없습니다.\")\n",
    "        \n",
    "        # 결측값 처리\n",
    "        movies_df['title'] = movies_df['title'].fillna('')\n",
    "        movies_df['overview'] = movies_df['overview'].fillna('')\n",
    "        movies_df['genres'] = movies_df['genres'].fillna('')\n",
    "        \n",
    "        # 줄거리 텍스트 정제\n",
    "        movies_df['overview_clean'] = movies_df['overview'].apply(self.enhanced_text_preprocessing)\n",
    "        \n",
    "        # 키워드 추출\n",
    "        print(\"키워드 추출 중...\")\n",
    "        movies_df['keywords'] = movies_df['overview'].apply(self.extract_keywords)\n",
    "        movies_df['keywords_text'] = movies_df['keywords'].apply(lambda x: ' '.join(x) if x else '')\n",
    "        \n",
    "        self.movie_data = movies_df.copy()\n",
    "        \n",
    "        # 1. 제목 TF-IDF 벡터화\n",
    "        print(\"제목 TF-IDF 벡터화 중...\")\n",
    "        self.tfidf_title = TfidfVectorizer(\n",
    "            max_features=5000,\n",
    "            stop_words=None,\n",
    "            ngram_range=(1, 2),\n",
    "            min_df=1\n",
    "        )\n",
    "        self.title_matrix = self.tfidf_title.fit_transform(movies_df['title'])\n",
    "        \n",
    "        # 2. 줄거리 TF-IDF 벡터화 (보조 특성)\n",
    "        print(\"줄거리 TF-IDF 벡터화 중...\")\n",
    "        self.tfidf_overview = TfidfVectorizer(\n",
    "            max_features=10000,\n",
    "            stop_words=None,\n",
    "            ngram_range=(1, 2),\n",
    "            min_df=1\n",
    "        )\n",
    "        overview_tfidf_matrix = self.tfidf_overview.fit_transform(movies_df['overview'])\n",
    "\n",
    "        # LSA (Truncated SVD)\n",
    "        self.svd = TruncatedSVD(n_components=100, random_state=42)\n",
    "        self.overview_matrix = self.svd.fit_transform(overview_tfidf_matrix)\n",
    "        \n",
    "        # 3. 키워드 TF-IDF 벡터화\n",
    "        print(\"키워드 TF-IDF 벡터화 중...\")\n",
    "        self.tfidf_keywords = TfidfVectorizer(\n",
    "            max_features=1000,\n",
    "            stop_words=None,\n",
    "            ngram_range=(1, 2),\n",
    "            min_df=1\n",
    "        )\n",
    "        self.keyword_matrix = self.tfidf_keywords.fit_transform(movies_df['keywords_text'])\n",
    "        \n",
    "        # 4. 장르 처리\n",
    "        print(\"장르 처리 중...\")\n",
    "        genre_lists = []\n",
    "        for genres in movies_df['genres']:\n",
    "            if isinstance(genres, str) and genres:\n",
    "                genre_list = [g.strip() for g in genres.split(',')]\n",
    "                genre_lists.append(genre_list)\n",
    "            elif isinstance(genres, list):\n",
    "                genre_lists.append(genres)\n",
    "            else:\n",
    "                genre_lists.append([])\n",
    "        \n",
    "        self.mlb_genre = MultiLabelBinarizer()\n",
    "        self.genre_matrix = self.mlb_genre.fit_transform(genre_lists)\n",
    "\n",
    "        # 5. KoBERT 임베딩\n",
    "        if not force_recompute and os.path.exists(\"plot_embeddings.npy\"):\n",
    "            print(\"✅ 저장된 줄거리 임베딩을 불러옵니다.\")\n",
    "            self.plot_embeddings = np.load(\"plot_embeddings.npy\")\n",
    "        else:\n",
    "            print(\"🛠 줄거리 임베딩을 새로 생성합니다.\")\n",
    "            if self.kobert_model is None:\n",
    "                self.load_kobert_model()\n",
    "        \n",
    "            plot_embeddings = []\n",
    "            for i, overview in enumerate(movies_df['overview']):\n",
    "                if i % 50 == 0:\n",
    "                    print(f\"임베딩 진행률: {i}/{len(movies_df)}\")\n",
    "                embedding = self.get_kobert_embedding(overview)\n",
    "                plot_embeddings.append(embedding)\n",
    "\n",
    "            self.plot_embeddings = np.array(plot_embeddings)\n",
    "            np.save(\"plot_embeddings.npy\", self.plot_embeddings)\n",
    "            print(\"줄거리 임베딩 저장 완료: plot_embeddings.npy\")\n",
    "            print(\"데이터 전처리 완료\")\n",
    "    \n",
    "    def calculate_similarity_comprehensive(self, movie_idx, weights):\n",
    "        \"\"\"포괄적인 유사도 계산\"\"\"\n",
    "        \n",
    "        # 1. KoBERT 임베딩 기반 유사도 (의미적 유사도)\n",
    "        target_plot_embedding = self.plot_embeddings[movie_idx].reshape(1, -1)\n",
    "        kobert_similarities = cosine_similarity(target_plot_embedding, self.plot_embeddings)[0]\n",
    "        \n",
    "        # 2. 줄거리 TF-IDF 기반 유사도 (어휘적 유사도)\n",
    "        target_overview_vector = self.overview_matrix[movie_idx]\n",
    "        overview_similarities = cosine_similarity(target_overview_vector.reshape(1, -1), self.overview_matrix)[0]\n",
    "        \n",
    "        # 3. 제목 유사도\n",
    "        target_title_vector = self.title_matrix[movie_idx]\n",
    "        title_similarities = cosine_similarity(target_title_vector, self.title_matrix)[0]\n",
    "        \n",
    "        # 4. 키워드 유사도\n",
    "        target_keyword_vector = self.keyword_matrix[movie_idx]\n",
    "        keyword_similarities = cosine_similarity(target_keyword_vector, self.keyword_matrix)[0]\n",
    "        \n",
    "        # 5. 고급 장르 유사도\n",
    "        target_genres = self.movie_data.iloc[movie_idx]['genres'].split(',') if self.movie_data.iloc[movie_idx]['genres'] else []\n",
    "        target_genres = [g.strip() for g in target_genres]\n",
    "        \n",
    "        genre_similarities = []\n",
    "        for i in range(len(self.movie_data)):\n",
    "            candidate_genres = self.movie_data.iloc[i]['genres'].split(',') if self.movie_data.iloc[i]['genres'] else []\n",
    "            candidate_genres = [g.strip() for g in candidate_genres]\n",
    "            \n",
    "            similarity = self.calculate_genre_similarity_advanced(target_genres, candidate_genres)\n",
    "            genre_similarities.append(similarity)\n",
    "        \n",
    "        genre_similarities = np.array(genre_similarities)\n",
    "        \n",
    "        # 6. 가중 평균으로 최종 유사도 계산\n",
    "        final_similarities = (\n",
    "            weights['kobert'] * kobert_similarities +\n",
    "            weights['overview_tfidf'] * overview_similarities +\n",
    "            weights['title'] * title_similarities +\n",
    "            weights['keywords'] * keyword_similarities +\n",
    "            weights['genre'] * genre_similarities\n",
    "        )\n",
    "        \n",
    "        return (final_similarities, kobert_similarities, overview_similarities, \n",
    "                title_similarities, keyword_similarities, genre_similarities)\n",
    "    \n",
    "    def adaptive_weights(self, movie_idx):\n",
    "        \"\"\"영화 특성에 따른 적응적 가중치 계산\"\"\"\n",
    "        movie_info = self.movie_data.iloc[movie_idx]\n",
    "        \n",
    "        # 기본 가중치\n",
    "        weights = {\n",
    "            'kobert': 0.25,\n",
    "            'overview_tfidf': 0.25,\n",
    "            'title': 0.15,\n",
    "            'keywords': 0.20,\n",
    "            'genre': 0.15\n",
    "        }\n",
    "        \n",
    "        # 영화 특성에 따른 가중치 조정\n",
    "        \n",
    "        # 1. 줄거리 길이에 따른 조정\n",
    "        overview_length = len(movie_info['overview']) if movie_info['overview'] else 0\n",
    "        if overview_length > 300:  # 긴 줄거리\n",
    "            weights['kobert'] += 0.03\n",
    "            weights['overview_tfidf'] += 0.03\n",
    "            weights['title'] -= 0.03\n",
    "            weights['keywords'] -= 0.03\n",
    "        elif overview_length < 50:  # 짧은 줄거리\n",
    "            weights['title'] += 0.10\n",
    "            weights['genre'] += 0.10\n",
    "            weights['kobert'] -= 0.10\n",
    "            weights['overview_tfidf'] -= 0.10\n",
    "        \n",
    "        # 2. 장르 수에 따른 조정\n",
    "        genre_count = len(movie_info['genres'].split(',')) if movie_info['genres'] else 0\n",
    "        if genre_count > 3:  # 많은 장르\n",
    "            weights['genre'] += 0.05\n",
    "            weights['kobert'] -= 0.05\n",
    "        elif genre_count == 1:  # 단일 장르\n",
    "            weights['genre'] += 0.10\n",
    "            weights['overview_tfidf'] -= 0.05\n",
    "            weights['keywords'] -= 0.05\n",
    "        \n",
    "        # 3. 특정 장르에 대한 조정\n",
    "        genres = movie_info['genres'].lower() if movie_info['genres'] else ''\n",
    "        if 'sf' in genres or '액션' in genres:\n",
    "            weights['keywords'] += 0.05\n",
    "            weights['title'] -= 0.05\n",
    "        elif '로맨스' in genres or '드라마' in genres:\n",
    "            weights['kobert'] += 0.05\n",
    "            weights['overview_tfidf'] += 0.05\n",
    "            weights['keywords'] -= 0.05\n",
    "            weights['genre'] -= 0.05\n",
    "        \n",
    "        # 가중치 정규화\n",
    "        total_weight = sum(weights.values())\n",
    "        weights = {k: v/total_weight for k, v in weights.items()}\n",
    "        \n",
    "        return weights\n",
    "    \n",
    "    def recommend_movies(self, movie_title=None, movie_idx=None, top_n=10, weights=None, use_adaptive_weights=True):\n",
    "        \"\"\"영화 추천\"\"\"\n",
    "        \n",
    "        if movie_idx is None:\n",
    "            if movie_title is None:\n",
    "                raise ValueError(\"movie_title 또는 movie_idx 중 하나는 제공되어야 합니다.\")\n",
    "            \n",
    "            # 제목으로 인덱스 찾기\n",
    "            matches = self.movie_data[self.movie_data['title'].str.contains(movie_title, case=False, na=False)]\n",
    "            if matches.empty:\n",
    "                print(f\"'{movie_title}'과 일치하는 영화를 찾을 수 없습니다.\")\n",
    "                return None\n",
    "            \n",
    "            movie_idx = matches.index[0]\n",
    "            actual_title = matches.iloc[0]['title']\n",
    "        else:\n",
    "            actual_title = self.movie_data.iloc[movie_idx]['title']\n",
    "        \n",
    "        # 가중치 결정\n",
    "        if use_adaptive_weights:\n",
    "            weights = self.adaptive_weights(movie_idx)\n",
    "            print(f\"적응적 가중치 사용: {weights}\")\n",
    "        elif weights is None:\n",
    "            weights = {\n",
    "                'kobert': 0.15,\n",
    "                'overview_tfidf': 0.35,\n",
    "                'title': 0.10,\n",
    "                'keywords': 0.25,\n",
    "                'genre': 0.15\n",
    "            }\n",
    "        \n",
    "        print(f\"\\n기준 영화: {actual_title}\")\n",
    "        print(f\"장르: {self.movie_data.iloc[movie_idx]['genres']}\")\n",
    "        print(f\"줄거리: {self.movie_data.iloc[movie_idx]['overview'][:200]}...\")\n",
    "        \n",
    "        # 유사도 계산\n",
    "        similarities = self.calculate_similarity_comprehensive(movie_idx, weights)\n",
    "        final_similarities = similarities[0]\n",
    "        \n",
    "        # 자기 자신 제외하고 상위 N개 추천\n",
    "        similar_indices = np.argsort(final_similarities)[::-1][1:top_n+1]\n",
    "        \n",
    "        # 추천 결과 생성\n",
    "        recommendations = []\n",
    "        for idx in similar_indices:\n",
    "            movie_info = {\n",
    "                'title': self.movie_data.iloc[idx]['title'],\n",
    "                'genres': self.movie_data.iloc[idx]['genres'],\n",
    "                'overview': self.movie_data.iloc[idx]['overview'],\n",
    "                'keywords': self.movie_data.iloc[idx]['keywords'],\n",
    "                'total_similarity': final_similarities[idx],\n",
    "                'kobert_similarity': similarities[1][idx],\n",
    "                'overview_tfidf_similarity': similarities[2][idx],\n",
    "                'title_similarity': similarities[3][idx],\n",
    "                'keyword_similarity': similarities[4][idx],\n",
    "                'genre_similarity': similarities[5][idx]\n",
    "            }\n",
    "            recommendations.append(movie_info)\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def display_recommendations(self, recommendations):\n",
    "        \"\"\"추천 결과 출력\"\"\"\n",
    "        if not recommendations:\n",
    "            print(\"추천할 영화가 없습니다.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n=== 추천 영화 TOP {len(recommendations)} ===\")\n",
    "        \n",
    "        for i, movie in enumerate(recommendations, 1):\n",
    "            print(f\"\\n{i}. {movie['title']}\")\n",
    "            print(f\"   장르: {movie['genres']}\")\n",
    "            print(f\"   총 유사도: {movie['total_similarity']:.3f}\")\n",
    "            print(f\"   세부 유사도:\")\n",
    "            print(f\"     - KoBERT: {movie['kobert_similarity']:.3f}\")\n",
    "            print(f\"     - 줄거리 TF-IDF: {movie['overview_tfidf_similarity']:.3f}\")\n",
    "            print(f\"     - 제목: {movie['title_similarity']:.3f}\")\n",
    "            print(f\"     - 키워드: {movie['keyword_similarity']:.3f}\")\n",
    "            print(f\"     - 장르: {movie['genre_similarity']:.3f}\")\n",
    "            print(f\"   키워드: {movie['keywords']}\")\n",
    "            print(f\"   줄거리: {movie['overview'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28a7ecbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 전처리 중...\n",
      "키워드 추출 중...\n",
      "제목 TF-IDF 벡터화 중...\n",
      "줄거리 TF-IDF 벡터화 중...\n",
      "키워드 TF-IDF 벡터화 중...\n",
      "장르 처리 중...\n",
      "✅ 저장된 줄거리 임베딩을 불러옵니다.\n",
      "=== 8월의 크리스마스 기반 추천 (적응적 가중치) ===\n",
      "적응적 가중치 사용: {'kobert': 0.3, 'overview_tfidf': 0.3, 'title': 0.15, 'keywords': 0.15000000000000002, 'genre': 0.09999999999999999}\n",
      "\n",
      "기준 영화: 8월의 크리스마스\n",
      "장르: 드라마, 로맨스\n",
      "줄거리: \"좋아하는 남자 친구 없어요?\" 변두리 사진관에서 아버지를 모시고 사는 노총각 ‘정원’. 시한부 인생을 받아들이고 가족, 친구들과 담담한 이별을 준비하던 어느 날, 주차단속요원 '다림'을 만나게 되고 차츰 평온했던 일상이 흔들리기 시작한다. \"아저씨, 왜 나만 보면 웃어요?\" 밝고 씩씩하지만 무료한 일상에 지쳐가던 스무 살 주차단속요원 '다림'. 단속차량 ...\n",
      "\n",
      "=== 추천 영화 TOP 10 ===\n",
      "\n",
      "1. 나를 잊지 말아요\n",
      "   장르: 드라마, 로맨스, 미스터리\n",
      "   총 유사도: 0.441\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.891\n",
      "     - 줄거리 TF-IDF: 0.334\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.114\n",
      "     - 장르: 0.562\n",
      "   키워드: ['사랑', '눈물', '가족', '신', '가족', '친구', '병원', '눈물', '행복', '사랑']\n",
      "   줄거리: 교통사고 후, 지난 10년의 기억이 지워진 남자 석원. 친구, 가족, 심지어 본인이 어떤 사람인지조차 흐릿해진 석원은 병원에서 우연히 자신을 보며 눈물을 흘리는 낯선 여자 진영을 ...\n",
      "\n",
      "2. 화려한 휴가\n",
      "   장르: 드라마, 역사\n",
      "   총 유사도: 0.431\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.872\n",
      "     - 줄거리 TF-IDF: 0.241\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.437\n",
      "     - 장르: 0.316\n",
      "   키워드: ['가족', '신', '말', '적', '가족', '친구', '일상']\n",
      "   줄거리: 광주에 사는 택시기사 민우. 어릴 적 부모님을 여의고 끔찍이 아끼는 동생 진우와 단둘이 사는 그는 오직 진우 하나만을 바라보며 평범한 일상을 살고 있다. 진우와 같은 성당에 다니는...\n",
      "\n",
      "3. 리틀 포레스트\n",
      "   장르: 드라마\n",
      "   총 유사도: 0.425\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.859\n",
      "     - 줄거리 TF-IDF: 0.380\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.053\n",
      "     - 장르: 0.455\n",
      "   키워드: ['용', '적', '친구', '서울']\n",
      "   줄거리: 서울에서 임용고시를 준비하던 혜원은 어느 겨울, 문득 짐을 챙겨 고향 미성리로 향한다. 집에 도착한 그녀가 가장 먼저 한 일은 꽝꽝 언 땅에 묻힌 배추를 꺼내 얼큰한 배춧국을 끓여...\n",
      "\n",
      "4. 동감\n",
      "   장르: 드라마, 로맨스\n",
      "   총 유사도: 0.425\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.816\n",
      "     - 줄거리 TF-IDF: 0.317\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.031\n",
      "     - 장르: 0.805\n",
      "   키워드: ['사랑', '용', '적', '친구', '사랑', '우정']\n",
      "   줄거리: 1999년, 용은 첫눈에 반하게 된 한솔을 사로잡기 위해 친구에게 HAM 무전기를 빌린다. 2022년, 무늬는 인터뷰 과제를 위해 오래된 HAM 무전기를 작동시킨다. 개기 월식이 ...\n",
      "\n",
      "5. 경주\n",
      "   장르: 드라마, 로맨스\n",
      "   총 유사도: 0.424\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.851\n",
      "     - 줄거리 TF-IDF: 0.294\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.000\n",
      "     - 장르: 0.805\n",
      "   키워드: ['적', '화가', '달']\n",
      "   줄거리: 친한 형의 장례식 소식에 오랜만에 한국을 찾은 북경대 교수 최현은 문득 7년 전 죽은 형과 함께 봤던 춘화 한 장을 떠올려 충동적으로 경주로 향한다. 춘화가 있던 찻집을 찾은 최현...\n",
      "\n",
      "6. 그해 여름\n",
      "   장르: 드라마, 로맨스\n",
      "   총 유사도: 0.421\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.868\n",
      "     - 줄거리 TF-IDF: 0.268\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.000\n",
      "     - 장르: 0.805\n",
      "   키워드: ['사랑', '첫사랑', '취재', '절친', '작가', '대학', '사랑']\n",
      "   줄거리: 모두가 동경하는 윤석영 교수의 첫사랑 서정인을 찾아 나선 TV 교양프로그램의 덜렁이 작가 수진. 낭만이라고는 약에 쓸래도 없는 앙숙 김PD와 취재길에 나선다. 윤석영 교수가 대학시...\n",
      "\n",
      "7. 한여름의 판타지아\n",
      "   장르: 드라마, 로맨스\n",
      "   총 유사도: 0.420\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.888\n",
      "     - 줄거리 TF-IDF: 0.210\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.065\n",
      "     - 장르: 0.805\n",
      "   키워드: ['고백', '용', '신', '아버지', '도시', '꿈']\n",
      "   줄거리: 영화감독 태훈은 새 영화를 찍기 위해 일본의 지방 소도시인 나라현 고조시를 방문한다. 조감독 미정과 함께 쇠락해가는 마을 곳곳을 누비며 그 곳에 사는 사람들을 인터뷰하고, 마을 사...\n",
      "\n",
      "8. 파이란\n",
      "   장르: 드라마, 로맨스\n",
      "   총 유사도: 0.419\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.865\n",
      "     - 줄거리 TF-IDF: 0.215\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.099\n",
      "     - 장르: 0.805\n",
      "   키워드: ['인생', '용', '신', '말', '조직', '친구', '달', '꿈']\n",
      "   줄거리: 인천에서 3류 양아치로 전전하던 강재는 불법 테입을 유통시키다가 걸려 열흘 간의 구류를 살다 돌아올 만큼 보잘 것 없는 삼류건달. 한창 때 같이 구르던 친구 용식은 어느새 조직을 ...\n",
      "\n",
      "9. 발레 교습소\n",
      "   장르: 드라마\n",
      "   총 유사도: 0.418\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.791\n",
      "     - 줄거리 TF-IDF: 0.174\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.553\n",
      "     - 장르: 0.455\n",
      "   키워드: ['가족', '인생', '신', '적', '가족', '아버지', '학교']\n",
      "   줄거리: 암투병 중이던 엄마가 돌아가신 지 1년, 아버지가 내내 어렵고 불편한 한없이 평범하고 수줍은 고 3 수험생 민재. 삼총사인 댄싱 킹카 창섭, 철없는 분위기 메이커 동완과 함께 수능...\n",
      "\n",
      "10. 연애소설\n",
      "   장르: 드라마, 로맨스\n",
      "   총 유사도: 0.417\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.840\n",
      "     - 줄거리 TF-IDF: 0.219\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.127\n",
      "     - 장르: 0.805\n",
      "   키워드: ['사랑', '고백', '용', '신', '서부', '말', '적', '아들', '친구', '달', '사랑', '우정']\n",
      "   줄거리: 어느 날, 지환(차태현 분)의 카메라 속으로 불쑥 수인(손예진 분)과 경희(이은주 분)가 들어온다. 닮은 듯 다른 두 사람, 수인과 경희는 둘도 없는 친구 사이. 수인에게 첫 눈에...\n",
      "\n",
      "=== 아바타 기반 추천 (적응적 가중치) ===\n",
      "적응적 가중치 사용: {'kobert': 0.23000000000000004, 'overview_tfidf': 0.28, 'title': 0.06999999999999999, 'keywords': 0.22000000000000003, 'genre': 0.2}\n",
      "\n",
      "기준 영화: 아바타\n",
      "장르: SF, 모험, 액션, 판타지\n",
      "줄거리: 가까운 미래, 지구는 에너지 고갈 문제를 해결하기 위해 머나먼 행성 판도라에서 대체 자원을 채굴하기 시작한다. 하지만 판도라의 독성을 지닌 대기로 인해 자원 획득에 어려움을 겪게 된 인류는 판도라의 토착민 나비의 외형에 인간의 의식을 주입, 원격 조종이 가능한 새로운 생명체를 탄생시키는 프로그램을 개발한다. 한편 하반신이 마비된 전직 해병대원 제이크 설리는...\n",
      "\n",
      "=== 추천 영화 TOP 8 ===\n",
      "\n",
      "1. 반지의 제왕: 왕의 귀환\n",
      "   장르: 모험, 액션, 판타지\n",
      "   총 유사도: 0.572\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.833\n",
      "     - 줄거리 TF-IDF: 0.288\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.799\n",
      "     - 장르: 0.620\n",
      "   키워드: ['전투', '인간', '미래', '신', '왕', '미래', '달']\n",
      "   줄거리: 사우론이 인간들의 마지막 요새인 곤도르를 향해 야욕을 드러내고 있는 한편, 아라곤은 쇠락해가고 있는 곤도르의 재건을 위해 왕위 계승을 신중하게 결정지어야만 하는 상황. 이제 중간대...\n",
      "\n",
      "2. 외계+인 2부\n",
      "   장르: 모험, 액션, 판타지\n",
      "   총 유사도: 0.505\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.869\n",
      "     - 줄거리 TF-IDF: 0.336\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.394\n",
      "     - 장르: 0.620\n",
      "   키워드: ['추격', '폭발', '인간', '미래', '외계', '신', '미래', '외계']\n",
      "   줄거리: 인간의 뇌 속에 갇혀 있는 외계인 포로들의 탈출을 막으려다 먼 과거에 갇혀버린 이안과 썬더는 시간을 관통하는 문을 열 수 있는 신검을 얻게 된다. 한편, 이안의 탈출을 도왔던 무륵...\n",
      "\n",
      "3. 투모로우 워\n",
      "   장르: SF, 모험, 액션\n",
      "   총 유사도: 0.455\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.823\n",
      "     - 줄거리 TF-IDF: 0.351\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.224\n",
      "     - 장르: 0.592\n",
      "   키워드: ['전쟁', '운명', '미래', '과학', '외계', '용', '팀', '적', '아버지', '딸', '팀', '군인', '과학자', '전쟁', '미래', '외계', '희망']\n",
      "   줄거리: 현재로 긴급 메시지를 전하기 위해 2051년에서 온 한 무리의 시간 여행자들이 도착한다. 메세지의 내용은 30년 동안 미래 인류가 치명적인 외계 종족과 세계 전쟁에서 지고 있다는 ...\n",
      "\n",
      "4. 맨 오브 스틸\n",
      "   장르: SF, 모험, 액션\n",
      "   총 유사도: 0.454\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.895\n",
      "     - 줄거리 TF-IDF: 0.346\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.149\n",
      "     - 장르: 0.592\n",
      "   키워드: ['신', '말', '왕', '장군', '아들', '행성', '실패']\n",
      "   줄거리: 무리한 자원 채취로 크립톤 행성의 종말이 다가오자 조드 장군은 반란을 일으켜 자신들만의 왕국을 건설하려 한다. 이에 반대한 조엘은 크립톤인의 유전자 정보가 담긴 코덱스를 빼돌려 이...\n",
      "\n",
      "5. 아바타: 물의 길\n",
      "   장르: SF, 모험, 액션\n",
      "   총 유사도: 0.427\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.699\n",
      "     - 줄거리 TF-IDF: 0.252\n",
      "     - 제목: 0.556\n",
      "     - 키워드: 0.176\n",
      "     - 장르: 0.592\n",
      "   키워드: ['전투', '가족', '가족', '행성']\n",
      "   줄거리: 판도라 행성에서 제이크 설리와 네이티리가 이룬 가족이 겪게 되는 무자비한 위협과 살아남기 위해 떠나야 하는 긴 여정과 전투, 그리고 견뎌내야 할 상처에 대한 이야기를 그렸다. 살아...\n",
      "\n",
      "6. 쥬라기 월드\n",
      "   장르: SF, 모험, 스릴러, 액션\n",
      "   총 유사도: 0.420\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.865\n",
      "     - 줄거리 TF-IDF: 0.244\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.255\n",
      "     - 장르: 0.482\n",
      "   키워드: ['인간', '적']\n",
      "   줄거리: 쥬라기 공원 사건에서 22년이 지난 후, 이슬라 누블라에서는 새로 열린 쥬라기 공원이 정상적으로 영업 중이다. 유전자 조작으로 탄생한 공룡들을 앞세운 쥬라기 월드는 지상 최대의 테...\n",
      "\n",
      "7. 미션 임파서블: 데드 레코닝\n",
      "   장르: 모험, 스릴러, 액션\n",
      "   총 유사도: 0.409\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.900\n",
      "     - 줄거리 TF-IDF: 0.091\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.471\n",
      "     - 장르: 0.362\n",
      "   키워드: ['작전', '추적', '미스터리', '미래', '신', '팀', '적', '팀', '미래']\n",
      "   줄거리: 모든 인류를 위협할 새로운 무기를 추적하게 된 에단 헌트와 IMF팀은 이 무기가 인류의 미래를 통제할 수 있다는 사실을 알게 된다. 전 세계가 위태로운 상황에 처한 가운데, 이를 ...\n",
      "\n",
      "8. 가디언즈 오브 갤럭시 Vol. 2\n",
      "   장르: SF, 모험, 액션\n",
      "   총 유사도: 0.403\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.838\n",
      "     - 줄거리 TF-IDF: 0.204\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.160\n",
      "     - 장르: 0.592\n",
      "   키워드: ['신', '아버지', '행성', '은하']\n",
      "   줄거리: 타노스에 맞서 은하계를 구하고 최고의 해결사로 등극한 스타로드 일행. 하지만 소버린 행성의 여사제 아이샤를 돕던 중 옛버릇을 고치지 못하고 행성의 배터리를 훔쳤다가 소버린 종족에 ...\n",
      "\n",
      "=== 해리 포터와 죽음의 성물 2 기반 추천 (적응적 가중치) ===\n",
      "적응적 가중치 사용: {'kobert': 0.28, 'overview_tfidf': 0.28, 'title': 0.12, 'keywords': 0.17, 'genre': 0.15}\n",
      "\n",
      "기준 영화: 해리 포터와 죽음의 성물 2\n",
      "장르: 모험, 판타지\n",
      "줄거리: 덤블도어 교장이 남긴 죽음의 성물의 단서를 쫓던 해리 포터는 볼드모트가 그토록 찾아 다닌 절대적인 힘을 가진 지팡이의 비밀을 통해 드디어 마지막 퍼즐을 완성한다. 볼드모트의 영혼이 담긴 다섯 번째 호크룩스를 찾기 위해 마법학교 호그와트로 돌아온 해리와 친구들은 그들을 잡으려는 보안마법에 걸려 위기를 맞지만 덤블도어의 동생인 에버포스의 도움으로 벗어난다. 그...\n",
      "\n",
      "=== 추천 영화 TOP 8 ===\n",
      "\n",
      "1. 해리 포터와 죽음의 성물 1\n",
      "   장르: 모험, 판타지\n",
      "   총 유사도: 0.726\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.953\n",
      "     - 줄거리 TF-IDF: 0.636\n",
      "     - 제목: 1.000\n",
      "     - 키워드: 0.237\n",
      "     - 장르: 0.805\n",
      "   키워드: ['마법', '친구']\n",
      "   줄거리: 덤블도어 교장의 죽음 이후, 마법부는 죽음을 먹는 자들에게 점령당하고 호그와트는 위기에 빠진다. 성년이 되며 해리를 지켜주던 수호 마법은 사라지고 해리와 론, 헤르미온느는 볼드모트...\n",
      "\n",
      "2. 해리 포터와 불사조 기사단\n",
      "   장르: 모험, 판타지\n",
      "   총 유사도: 0.644\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.910\n",
      "     - 줄거리 TF-IDF: 0.492\n",
      "     - 제목: 0.337\n",
      "     - 키워드: 0.534\n",
      "     - 장르: 0.805\n",
      "   키워드: ['마법', '용', '마법사', '이모', '친구', '학교']\n",
      "   줄거리: 길고도 지루한 여름 날 호그와트 마법학교 다섯 번째 해를 기다리고 있는 해리포터. 이모부 더즐리 식구들과 참고 사는 것도 지겨운데다 친구 론과 헤르미온느에게서는 편지 한 통 오지 ...\n",
      "\n",
      "3. 해리 포터와 혼혈왕자\n",
      "   장르: 모험, 판타지\n",
      "   총 유사도: 0.609\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.925\n",
      "     - 줄거리 TF-IDF: 0.550\n",
      "     - 제목: 0.414\n",
      "     - 키워드: 0.152\n",
      "     - 장르: 0.805\n",
      "   키워드: ['전투', '미션', '정의', '로맨스', '신', '대장', '적', '친구', '학교', '정의']\n",
      "   줄거리: 어둠의 세력이 더욱 강력해져 머글 세계와 호그와트까지 위협해온다. 위험한 기운을 감지한 덤블도어 교수는 다가올 전투에 대비하기 위해 해리 포터와 함께 대장정의 길을 나선다. 볼드모...\n",
      "\n",
      "4. 해리 포터와 불의 잔\n",
      "   장르: 모험, 판타지\n",
      "   총 유사도: 0.527\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.845\n",
      "     - 줄거리 TF-IDF: 0.270\n",
      "     - 제목: 0.414\n",
      "     - 키워드: 0.258\n",
      "     - 장르: 0.805\n",
      "   키워드: ['마법', '신', '왕', '친구', '학교']\n",
      "   줄거리: 요즘 들어 매일 꾸는 악몽 때문에 이마의 상처에 더욱 통증을 느끼는 해리는 친구 론과 헤르미온느와 함께 퀴디치 월드컵에 참가해 악몽에서 벗어날 수 있게 돼 마냥 기쁘다. 그러나 퀴...\n",
      "\n",
      "5. 해리 포터와 아즈카반의 죄수\n",
      "   장르: 모험, 판타지\n",
      "   총 유사도: 0.511\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.910\n",
      "     - 줄거리 TF-IDF: 0.279\n",
      "     - 제목: 0.337\n",
      "     - 키워드: 0.098\n",
      "     - 장르: 0.805\n",
      "   키워드: ['공포', '괴물', '가족', '마법', '용', '술집', '적', '가족', '이모', '학교', '우울', '스트레스', '우울']\n",
      "   줄거리: 13세가 된 해리 포터는 또 한번의 여름 방학을 이모 가족인 더즐리 일가와 우울하게 보내야 했다. 물론 마법을 쓰는 건 일체 금지. 하지만, 버논 이모부의 누이인 마지 아줌마가 더...\n",
      "\n",
      "6. 해리 포터와 비밀의 방\n",
      "   장르: 모험, 판타지\n",
      "   총 유사도: 0.495\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.828\n",
      "     - 줄거리 TF-IDF: 0.253\n",
      "     - 제목: 0.427\n",
      "     - 키워드: 0.118\n",
      "     - 장르: 0.805\n",
      "   키워드: ['고백', '무서운', '가족', '마법', '요정', '신', '가족', '형제', '이모', '학교']\n",
      "   줄거리: 해리 포터에겐 이번 여름방학이 별로 즐겁질 못했다. 마법이라면 질색을 하는 페투니아 이모와 버논 이모부의 구박도 그렇지만, 무엇보다 속상한 건 단짝이었던 론 위즐리와 헤르미온느 그...\n",
      "\n",
      "7. 해리 포터와 마법사의 돌\n",
      "   장르: 모험, 판타지\n",
      "   총 유사도: 0.492\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.860\n",
      "     - 줄거리 TF-IDF: 0.288\n",
      "     - 제목: 0.414\n",
      "     - 키워드: 0.000\n",
      "     - 장르: 0.805\n",
      "   키워드: ['용', '신', '대장', '적', '이모', '숙부', '달', '입학']\n",
      "   줄거리: 해리 포터는 위압적인 버논 숙부와 냉담한 이모 페투니아, 욕심 많고 버릇없는 사촌 더즐리 밑에서 갖은 구박을 견디며 계단 밑 벽장에서 생활한다. 이모네 식구들 역시 해리와의 동거가...\n",
      "\n",
      "8. 반지의 제왕: 반지 원정대\n",
      "   장르: 모험, 액션, 판타지\n",
      "   총 유사도: 0.488\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.871\n",
      "     - 줄거리 TF-IDF: 0.302\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.414\n",
      "     - 장르: 0.597\n",
      "   키워드: ['인간', '마법', '용', '마법사', '신', '삼촌', '친구', '달']\n",
      "   줄거리: 호빗이라 불리우는 난장이 종족 중의 한 명인 프로도는 자신의 삼촌에게서 우연히 절대 반지를 물려받게 되고, 마법사 간달프를 통해서 절대반지가 사우론의 손에 들어가면 악의 세력이 세...\n"
     ]
    }
   ],
   "source": [
    "# 사용 예시\n",
    "\n",
    "def create_extended_sample_data():\n",
    "    # movie_data.csv 파일을 불러와서 DataFrame 반환\n",
    "    df = pd.read_csv('./tranning-data/movie_data.csv', encoding='utf-8-sig')\n",
    "    return df\n",
    "\n",
    "# 실행 예시\n",
    "if __name__ == \"__main__\":\n",
    "    # 확장된 샘플 데이터 생성\n",
    "    movies_df = create_extended_sample_data()\n",
    "    \n",
    "    # 개선된 추천 시스템 초기화\n",
    "    recommender = ImprovedMovieRecommendationSystem()\n",
    "    \n",
    "    # 데이터 전처리\n",
    "    recommender.prepare_data(movies_df)\n",
    "    \n",
    "    # 적응적 가중치로 추천\n",
    "    print(\"=== 8월의 크리스마스 기반 추천 (적응적 가중치) ===\")\n",
    "    recommendations1 = recommender.recommend_movies(\n",
    "        movie_title='8월의 크리스마스',\n",
    "        top_n=10,\n",
    "        use_adaptive_weights=True\n",
    "    )\n",
    "    recommender.display_recommendations(recommendations1)\n",
    "    \n",
    "    # 다른 영화로 테스트\n",
    "    print(\"\\n=== 아바타 기반 추천 (적응적 가중치) ===\")\n",
    "    recommendations2 = recommender.recommend_movies(\n",
    "        movie_title='아바타',\n",
    "        top_n=8,\n",
    "        use_adaptive_weights=True\n",
    "    )\n",
    "    recommender.display_recommendations(recommendations2)\n",
    "    \n",
    "    # 로맨스 영화로 테스트\n",
    "    print(\"\\n=== 해리 포터와 죽음의 성물 2 기반 추천 (적응적 가중치) ===\")\n",
    "    recommendations3 = recommender.recommend_movies(\n",
    "        movie_title='해리 포터와 죽음의 성물 2',\n",
    "        top_n=8,\n",
    "        use_adaptive_weights=True\n",
    "    )\n",
    "    recommender.display_recommendations(recommendations3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10c0068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 추천 개선\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from collections import Counter\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "class ImprovedMovieRecommendationSystem:\n",
    "    def __init__(self, stopword_files = None, cache_dir=\"./cached_features\"):\n",
    "        self.kobert_tokenizer = None\n",
    "        self.kobert_model = None\n",
    "        self.tfidf_title = None\n",
    "        self.tfidf_overview = None\n",
    "        self.tfidf_keywords = None\n",
    "        self.mlb_genre = None\n",
    "        self.movie_data = None\n",
    "        self.plot_embeddings = None\n",
    "        self.title_matrix = None\n",
    "        self.genre_matrix = None\n",
    "        self.keyword_matrix = None\n",
    "        self.overview_matrix = None\n",
    "\n",
    "        # 불용어 파일 리스트가 제공되면 로드, 아니면 기본 빈 set\n",
    "        if stopword_files is None:\n",
    "            # 기본 불용어 파일 (예시: 프로젝트 내에 git_stopwords.txt 하나만 있는 경우)\n",
    "            # 또는 비어있는 set으로 시작하여 불용어 처리를 하지 않을 수도 있습니다.\n",
    "            stopword_files = [\"git_stopwords.txt\"] # 기본 파일 경로 지정\n",
    "        \n",
    "        self.custom_stopwords = self.load_stopwords_from_files(stopword_files)\n",
    "        \n",
    "    def load_kobert_model(self):\n",
    "        \"\"\"KoBERT 모델 로드\"\"\"\n",
    "        print(\"KoBERT 모델 로딩 중...\")\n",
    "        model_name = \"monologg/kobert\"\n",
    "        self.kobert_model = AutoModel.from_pretrained(model_name)\n",
    "        self.kobert_tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "        self.kobert_model.eval()\n",
    "        print(\"KoBERT 모델 로드 완료\")\n",
    "\n",
    "    def enhanced_text_preprocessing(self, text):\n",
    "        \"\"\"텍스트 전처리 강화\"\"\"\n",
    "        if not text or pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        text = str(text)\n",
    "        \n",
    "        # 특수 문자 및 숫자 처리\n",
    "        text = re.sub(r'[^\\w\\s가-힣a-zA-Z0-9]', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        \n",
    "        return text.strip()\n",
    "\n",
    "    def extract_nouns_from_text(self, text, okt):\n",
    "        \"\"\"텍스트에서 명사 추출\"\"\"\n",
    "        if not text:\n",
    "            return []\n",
    "        \n",
    "        # 명사 추출\n",
    "        nouns = okt.nouns(text)\n",
    "        \n",
    "        # 단어 길이가 1 이하인 것 제거\n",
    "        filtered_nouns = [noun for noun in nouns if len(noun) > 1]\n",
    "        \n",
    "        return filtered_nouns\n",
    "    \n",
    "    def load_stopwords_from_files(self, stopword_files):\n",
    "        \"\"\"여러 불용어 파일을 로드하여 하나의 set으로 통합\"\"\"\n",
    "        combined_stopwords = set()\n",
    "        \n",
    "        base_dir = \"./stopwords/\"\n",
    "\n",
    "        for file_name in stopword_files:\n",
    "            file_path = os.path.join(base_dir, file_name)\n",
    "\n",
    "            if os.path.exists(file_path):\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        words = [line.strip() for line in f if line.strip()]\n",
    "                        combined_stopwords.update(words)\n",
    "                    print(f\"불용어 파일 로드 완료: {file_path} ({len(words)}개)\")\n",
    "                except Exception as e:\n",
    "                    print(f\"불용어 파일 로드 실패: {file_path} - {e}\")\n",
    "    \n",
    "        if not combined_stopwords: # 로드된 불용어가 없을 경우 (파일이 없거나 비어있을 때)\n",
    "            print(\"❗ 모든 불용어 파일을 로드할 수 없거나 파일이 비어 있어 기본 불용어를 사용합니다.\")\n",
    "            # 예비 불용어 리스트를 set으로 변환\n",
    "            return set(['하다', '있다', '없다', '되다', '이다', '것', '수', '점', '말', '안', '때', '등', '통해'])\n",
    "        \n",
    "        return combined_stopwords\n",
    "\n",
    "    def enhanced_text_preprocessing_kobert(self, text):\n",
    "        if pd.isna(text) or not text:\n",
    "            return \"\"\n",
    "\n",
    "        text = self.enhanced_text_preprocessing(text)\n",
    "        stopwords_pos = ['Josa', 'Eomi', 'Suffix', 'Punctuation'] \n",
    "        \n",
    "        tokens = self.okt.pos(text, norm=True, stem=True)\n",
    "        \n",
    "        filtered_tokens = []\n",
    "        for word, pos in tokens:\n",
    "            if pos not in stopwords_pos:\n",
    "                # 함수 내부에서 로드한 custom_stopwords 사용\n",
    "                if word not in self.custom_stopwords: \n",
    "                    filtered_tokens.append(word)\n",
    "        \n",
    "        return ' '.join(filtered_tokens)\n",
    "    \n",
    "    def extract_keywords(self, text):\n",
    "        \"\"\"텍스트에서 키워드 추출 (형태소 분석 + 불용어 제거 + 가중치 적용)\"\"\"\n",
    "        if not text or pd.isna(text):\n",
    "            return []\n",
    "        \n",
    "        # OKT 형태소 분석기 초기화 (클래스 변수로 관리하면 더 효율적)\n",
    "        if not hasattr(self, 'okt'):\n",
    "            self.okt = Okt()\n",
    "        \n",
    "        # 불용어 로드 (처음 한 번만 실행)\n",
    "        if not hasattr(self, 'stopwords'):\n",
    "            stopword_files = [\n",
    "                'common_name_stopwords.txt',\n",
    "                'korean_adverb_stopwords.txt', \n",
    "                'general_stopwords.txt',\n",
    "                'git_stopwords.txt'\n",
    "            ]\n",
    "            self.stopwords = self.load_stopwords_from_files(stopword_files)\n",
    "            print(f\"전체 불용어 개수: {len(self.stopwords)}\")\n",
    "        \n",
    "        # 한국어 영화 관련 키워드 패턴 (가중치 포함)\n",
    "        movie_keywords = {\n",
    "            # 장르 관련 (가중치 2)\n",
    "            'action': {\n",
    "                'weight': 2,\n",
    "                'keywords': [\n",
    "                    '액션', '전투', '싸움', '전쟁', '격투', '추격', '폭발', '총격',\n",
    "                    '무술', '카체이싱', '건파이트', '배틀', '액션스릴러', '느와르',\n",
    "                    '스파이', '첩보', '잠입', '미션', '작전', '복수', '정의', '위장'\n",
    "                ]\n",
    "            },\n",
    "            'romance': {\n",
    "                'weight': 2,\n",
    "                'keywords': [\n",
    "                    '사랑', '로맨스', '연인', '결혼', '연애', '첫사랑', '이별', '만남',\n",
    "                    '멜로', '러브스토리', '운명', '재회', '프로포즈', '웨딩', '데이트',\n",
    "                    '썸', '고백', '짝사랑', '원거리', '국제연애', '나이차', '사내연애'\n",
    "                ]\n",
    "            },\n",
    "            'comedy': {\n",
    "                'weight': 2,\n",
    "                'keywords': [\n",
    "                    '코미디', '웃음', '유머', '재미', '개그', '유쾌', '농담',\n",
    "                    '개그맨', '상황극', '슬랩스틱', '로맨틱코미디', '패밀리코미디',\n",
    "                    '블랙코미디', '풍자', '해학', '익살', '코믹', '유머러스'\n",
    "                ]\n",
    "            },\n",
    "            'horror': {\n",
    "                'weight': 2,\n",
    "                'keywords': [\n",
    "                    '공포', '호러', '무서운', '귀신', '좀비', '괴물', '악령',\n",
    "                    '사이코', '살인마', '연쇄살인', '초자연', '오컬트', '엑소시즘',\n",
    "                    '저주', '원혼', '귀신', '유령', '무덤', '폐가', '심령', '위험구역'\n",
    "                ]\n",
    "            },\n",
    "            'thriller': {\n",
    "                'weight': 2,\n",
    "                'keywords': [\n",
    "                    '스릴러', '긴장', '추적', '수사', '범죄', '살인', '미스터리',\n",
    "                    '서스펜스', '추리', '탐정', '형사', '검찰', '법정', '재판',\n",
    "                    '납치', '협박', '음모', '배신', '사기', '해킹', '첩보'\n",
    "                ]\n",
    "            },\n",
    "            'drama': {\n",
    "                'weight': 2,\n",
    "                'keywords': [\n",
    "                    '인간', '감동', '눈물', '인생', '성장'\n",
    "                ]\n",
    "            },\n",
    "            \n",
    "            # 테마/소재 관련 (가중치 1.5)\n",
    "            'theme': {\n",
    "                'weight': 1.5,\n",
    "                'keywords': [\n",
    "                    '복수', '정의', '우정', '배신', '희생',\n",
    "                    '성장', '자아실현', '꿈', '도전', '극복', '화해',\n",
    "                    '갈등', '대립', '협력', '경쟁', '성공', '실패'\n",
    "                ]\n",
    "            },\n",
    "            'emotion': {\n",
    "                'weight': 1.5,\n",
    "                'keywords': [\n",
    "                    '감동', '눈물', '슬픔', '기쁨', '행복', '분노',\n",
    "                    '절망', '희망', '사랑', '이별', '그리움', '향수',\n",
    "                    '외로움', '고독', '우울', '스트레스', '끔찍한'\n",
    "                ]\n",
    "            },\n",
    "            \n",
    "            # 배경/직업 관련 (가중치 1)\n",
    "            'profession': {\n",
    "                'weight': 1,\n",
    "                'keywords': [\n",
    "                    '의사', '변호사', '교사', '경찰', '소방관', '군인',\n",
    "                    '기자', '작가', '화가', '음악가', '요리사', '사업가',\n",
    "                    '정치인', '연예인', '운동선수', '과학자', '엔지니어'\n",
    "                ]\n",
    "            },\n",
    "            'background': {\n",
    "                'weight': 1,\n",
    "                'keywords': [\n",
    "                    '현대', '도시', '서울', '학교', '대학', '회사', '직장',\n",
    "                    '병원', '법원', '경찰서', '아파트', '카페'\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 1. 텍스트 전처리\n",
    "        preprocessed_text = self.enhanced_text_preprocessing(text)\n",
    "        \n",
    "        # 2. 형태소 분석으로 명사 추출\n",
    "        nouns = self.extract_nouns_from_text(preprocessed_text, self.okt)\n",
    "        \n",
    "        # 3. 불용어 제거\n",
    "        filtered_nouns = [noun for noun in nouns \n",
    "                        if noun not in self.stopwords]\n",
    "        \n",
    "        # 4. 명사 빈도 계산\n",
    "        noun_counts = Counter(filtered_nouns)\n",
    "        \n",
    "        # 5. 영화 키워드 매칭 및 가중치 적용\n",
    "        keyword_scores = {}\n",
    "        \n",
    "        for category, category_info in movie_keywords.items():\n",
    "            weight = category_info['weight']\n",
    "            keywords = category_info['keywords']\n",
    "            \n",
    "            for keyword in keywords:\n",
    "                # 키워드가 추출된 명사에 있는지 확인\n",
    "                if keyword in filtered_nouns:\n",
    "                    score = noun_counts[keyword] * weight\n",
    "                    if keyword in keyword_scores:\n",
    "                        keyword_scores[keyword] += score\n",
    "                    else:\n",
    "                        keyword_scores[keyword] = score\n",
    "        \n",
    "        # 6. 점수 기준으로 정렬하여 상위 키워드 반환\n",
    "        sorted_keywords = sorted(keyword_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # 상위 20개 키워드만 반환 (키워드만, 점수 제외)\n",
    "        top_keywords = [keyword for keyword, score in sorted_keywords[:20]]\n",
    "        \n",
    "        # 매칭되지 않은 중요 명사도 일부 포함 (빈도수 기준)\n",
    "        remaining_nouns = [noun for noun in noun_counts.most_common(10) \n",
    "                        if noun[0] not in top_keywords]\n",
    "        \n",
    "        # 최종 키워드 결합\n",
    "        final_keywords = top_keywords + [noun[0] for noun in remaining_nouns[:5]]\n",
    "        \n",
    "        return final_keywords[:25]  # 최대 25개 키워드 반환\n",
    "\n",
    "\n",
    "    def get_kobert_embedding(self, text):\n",
    "        \"\"\"KoBERT를 사용하여 텍스트 임베딩 생성\"\"\"\n",
    "        if not text or pd.isna(text):\n",
    "            return np.zeros(768)  # KoBERT 임베딩 차원\n",
    "        \n",
    "        text = self.enhanced_text_preprocessing(text)\n",
    "        \n",
    "        # 텍스트 길이 제한 (KoBERT 최대 입력 길이 고려)\n",
    "        text = str(text)[:512]\n",
    "        \n",
    "        inputs = self.kobert_tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=512\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.kobert_model(**inputs)\n",
    "            # [CLS] 토큰의 임베딩 사용\n",
    "            embedding = outputs.last_hidden_state[:, 0, :].squeeze().detach().cpu().numpy()\n",
    "        \n",
    "        return embedding\n",
    "    \n",
    "    def calculate_genre_similarity_advanced(self, target_genres, candidate_genres):\n",
    "        \"\"\"고급 장르 유사도 계산\"\"\"\n",
    "        # 장르 간 유사도 매트릭스 (실제로는 더 정교하게 구성 가능)\n",
    "        genre_similarity_matrix = {\n",
    "            '액션': {\n",
    "                '모험': 0.8,\n",
    "                'SF': 0.7,\n",
    "                '스릴러': 0.6,\n",
    "                '범죄': 0.5,\n",
    "                '판타지': 0.4,\n",
    "                '전쟁': 0.6,\n",
    "                '서부': 0.5\n",
    "            },\n",
    "            \n",
    "            '모험': {\n",
    "                '액션': 0.8,\n",
    "                '판타지': 0.7,\n",
    "                'SF': 0.6,\n",
    "                '가족': 0.6,\n",
    "                '애니메이션': 0.5,\n",
    "                '역사': 0.4\n",
    "            },\n",
    "            \n",
    "            '애니메이션': {\n",
    "                '가족': 0.8,\n",
    "                '코미디': 0.6,\n",
    "                '판타지': 0.5,\n",
    "                '모험': 0.5,\n",
    "                '로맨스': 0.4,\n",
    "                '드라마': 0.3\n",
    "            },\n",
    "            \n",
    "            '코미디': {\n",
    "                '로맨스': 0.5,\n",
    "                '드라마': 0.4,\n",
    "                '애니메이션': 0.6,\n",
    "                '가족': 0.5,\n",
    "                '음악': 0.3\n",
    "            },\n",
    "            \n",
    "            '범죄': {\n",
    "                '스릴러': 0.8,\n",
    "                '미스터리': 0.7,\n",
    "                '드라마': 0.6,\n",
    "                '액션': 0.5,\n",
    "                '공포': 0.4\n",
    "            },\n",
    "            \n",
    "            '다큐멘터리': {\n",
    "                '역사': 0.6,\n",
    "                '드라마': 0.4,\n",
    "                '음악': 0.3,\n",
    "                '전쟁': 0.3\n",
    "            },\n",
    "            \n",
    "            '드라마': {\n",
    "                '로맨스': 0.7,\n",
    "                '스릴러': 0.5,\n",
    "                '코미디': 0.4,\n",
    "                '범죄': 0.6,\n",
    "                '미스터리': 0.5,\n",
    "                '역사': 0.4,\n",
    "                '다큐멘터리': 0.4,\n",
    "                '가족': 0.5,\n",
    "                '음악': 0.4\n",
    "            },\n",
    "            \n",
    "            '가족': {\n",
    "                '애니메이션': 0.8,\n",
    "                '코미디': 0.5,\n",
    "                '모험': 0.6,\n",
    "                '판타지': 0.5,\n",
    "                '드라마': 0.5,\n",
    "                '로맨스': 0.4\n",
    "            },\n",
    "            \n",
    "            '판타지': {\n",
    "                '모험': 0.7,\n",
    "                'SF': 0.6,\n",
    "                '액션': 0.4,\n",
    "                '애니메이션': 0.5,\n",
    "                '가족': 0.5,\n",
    "                '공포': 0.5\n",
    "            },\n",
    "            \n",
    "            '역사': {\n",
    "                '드라마': 0.4,\n",
    "                '전쟁': 0.8,\n",
    "                '다큐멘터리': 0.6,\n",
    "                '모험': 0.4,\n",
    "                '서부': 0.5\n",
    "            },\n",
    "            \n",
    "            '공포': {\n",
    "                '스릴러': 0.7,\n",
    "                '미스터리': 0.6,\n",
    "                '판타지': 0.5,\n",
    "                'SF': 0.4,\n",
    "                '범죄': 0.4\n",
    "            },\n",
    "            \n",
    "            '음악': {\n",
    "                '드라마': 0.4,\n",
    "                '코미디': 0.3,\n",
    "                '로맨스': 0.5,\n",
    "                '다큐멘터리': 0.3\n",
    "            },\n",
    "            \n",
    "            '미스터리': {\n",
    "                '범죄': 0.7,\n",
    "                '스릴러': 0.8,\n",
    "                '공포': 0.6,\n",
    "                '드라마': 0.5\n",
    "            },\n",
    "            \n",
    "            '로맨스': {\n",
    "                '드라마': 0.7,\n",
    "                '코미디': 0.5,\n",
    "                '음악': 0.5,\n",
    "                '애니메이션': 0.4,\n",
    "                '가족': 0.4\n",
    "            },\n",
    "            \n",
    "            'SF': {\n",
    "                '액션': 0.7,\n",
    "                '모험': 0.6,\n",
    "                '판타지': 0.6,\n",
    "                '스릴러': 0.5,\n",
    "                '공포': 0.4\n",
    "            },\n",
    "            \n",
    "            '스릴러': {\n",
    "                '범죄': 0.8,\n",
    "                '미스터리': 0.8,\n",
    "                '공포': 0.7,\n",
    "                '액션': 0.6,\n",
    "                '드라마': 0.5,\n",
    "                'SF': 0.5\n",
    "            },\n",
    "            \n",
    "            '전쟁': {\n",
    "                '역사': 0.8,\n",
    "                '드라마': 0.6,\n",
    "                '액션': 0.6,\n",
    "                '다큐멘터리': 0.3\n",
    "            },\n",
    "            \n",
    "            '서부': {\n",
    "                '액션': 0.5,\n",
    "                '역사': 0.5,\n",
    "                '드라마': 0.4\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        if not target_genres or not candidate_genres:\n",
    "            return 0.0\n",
    "        \n",
    "        # 직접 매치 점수\n",
    "        direct_match = len(set(target_genres) & set(candidate_genres)) / len(set(target_genres) | set(candidate_genres))\n",
    "        \n",
    "        # 간접 매치 점수\n",
    "        indirect_score = 0\n",
    "        for target_genre in target_genres:\n",
    "            for candidate_genre in candidate_genres:\n",
    "                if target_genre.lower() in genre_similarity_matrix:\n",
    "                    if candidate_genre.lower() in genre_similarity_matrix[target_genre.lower()]:\n",
    "                        indirect_score += genre_similarity_matrix[target_genre.lower()][candidate_genre.lower()]\n",
    "        \n",
    "        indirect_score = indirect_score / (len(target_genres) * len(candidate_genres)) if target_genres and candidate_genres else 0\n",
    "        \n",
    "        return 0.7 * direct_match + 0.3 * indirect_score\n",
    "    \n",
    "    def prepare_data(self, movies_df, force_recompute=False):\n",
    "        \"\"\"데이터 전처리 및 특성 추출\"\"\"\n",
    "        print(\"데이터 전처리 중...\")\n",
    "        \n",
    "        # 필수 컬럼 확인\n",
    "        required_columns = ['title', 'overview', 'genres']\n",
    "        for col in required_columns:\n",
    "            if col not in movies_df.columns:\n",
    "                raise ValueError(f\"필수 컬럼 '{col}'이 데이터에 없습니다.\")\n",
    "        \n",
    "        # 결측값 처리\n",
    "        movies_df['title'] = movies_df['title'].fillna('')\n",
    "        movies_df['overview'] = movies_df['overview'].fillna('')\n",
    "        movies_df['genres'] = movies_df['genres'].fillna('')\n",
    "        \n",
    "        # 키워드 추출\n",
    "        print(\"키워드 추출 중...\")\n",
    "        movies_df['keywords'] = movies_df['overview'].apply(self.extract_keywords)\n",
    "        movies_df['keywords_text'] = movies_df['keywords'].apply(lambda x: ' '.join(x) if x else '')\n",
    "        \n",
    "        self.movie_data = movies_df.copy()\n",
    "        \n",
    "        processed_title = movies_df['title'].apply(self.enhanced_text_preprocessing_kobert)\n",
    "        # 1. 제목 TF-IDF 벡터화\n",
    "        print(\"제목 TF-IDF 벡터화 중...\")\n",
    "        self.tfidf_title = TfidfVectorizer(\n",
    "            max_features=5000,\n",
    "            stop_words=None,\n",
    "            ngram_range=(1, 2),\n",
    "            min_df=1\n",
    "        )\n",
    "        self.title_matrix = self.tfidf_title.fit_transform(processed_title)\n",
    "\n",
    "        # 2. 줄거리 TF-IDF 벡터화 (형태소 분리 적용)\n",
    "        processed_overviews = movies_df['overview'].apply(lambda x: self.enhanced_text_preprocessing_kobert(x))\n",
    "        \n",
    "        self.tfidf_overview = TfidfVectorizer(\n",
    "            max_features=10000, \n",
    "            stop_words=None, \n",
    "            ngram_range=(1, 2), \n",
    "            min_df=1 \n",
    "        )\n",
    "        overview_tfidf_matrix = self.tfidf_overview.fit_transform(processed_overviews)\n",
    "        print(\"줄거리 TF-IDF 벡터화 완료.\")\n",
    "\n",
    "        # LSA (Truncated SVD)\n",
    "        self.svd = TruncatedSVD(n_components=100, random_state=42)\n",
    "        self.overview_matrix = self.svd.fit_transform(overview_tfidf_matrix)\n",
    "        \n",
    "        # 3. 키워드 TF-IDF 벡터화\n",
    "        print(\"키워드 TF-IDF 벡터화 중...\")\n",
    "        self.tfidf_keywords = TfidfVectorizer(\n",
    "            max_features=1000,\n",
    "            stop_words=None,\n",
    "            ngram_range=(1, 1),\n",
    "            min_df=3,  # 최소 2개 영화에서 나타나는 키워드만 사용\n",
    "            max_df=0.4,  # 40% 이상 영화에 나타나는 키워드는 제외\n",
    "        )\n",
    "        self.keyword_matrix = self.tfidf_keywords.fit_transform(movies_df['keywords_text'])\n",
    "        \n",
    "        # 4. 장르 처리\n",
    "        print(\"장르 처리 중...\")\n",
    "        genre_lists = []\n",
    "        for genres in movies_df['genres']:\n",
    "            if isinstance(genres, str) and genres:\n",
    "                genre_list = [g.strip() for g in genres.split(',')]\n",
    "                genre_lists.append(genre_list)\n",
    "            elif isinstance(genres, list):\n",
    "                genre_lists.append(genres)\n",
    "            else:\n",
    "                genre_lists.append([])\n",
    "        \n",
    "        self.mlb_genre = MultiLabelBinarizer()\n",
    "        self.genre_matrix = self.mlb_genre.fit_transform(genre_lists)\n",
    "\n",
    "        # 5. KoBERT 임베딩\n",
    "        if not force_recompute and os.path.exists(\"plot_embeddings.npy\"):\n",
    "            print(\"✅ 저장된 줄거리 임베딩을 불러옵니다.\")\n",
    "            self.plot_embeddings = np.load(\"plot_embeddings.npy\")\n",
    "        else:\n",
    "            print(\"🛠 줄거리 임베딩을 새로 생성합니다.\")\n",
    "            if self.kobert_model is None:\n",
    "                self.load_kobert_model()\n",
    "        \n",
    "            plot_embeddings = []\n",
    "            for i, overview in enumerate(processed_overviews):\n",
    "                if i % 50 == 0:\n",
    "                    print(f\"임베딩 진행률: {i}/{len(movies_df)}\")\n",
    "                embedding = self.get_kobert_embedding(overview)\n",
    "                plot_embeddings.append(embedding)\n",
    "\n",
    "            self.plot_embeddings = np.array(plot_embeddings)\n",
    "            np.save(\"plot_embeddings.npy\", self.plot_embeddings)\n",
    "            print(\"줄거리 임베딩 저장 완료: plot_embeddings.npy\")\n",
    "            print(\"데이터 전처리 완료\")\n",
    "    \n",
    "    def calculate_similarity_comprehensive(self, movie_idx, weights):\n",
    "        \"\"\"포괄적인 유사도 계산\"\"\"\n",
    "        \n",
    "        # 1. KoBERT 임베딩 기반 유사도 (의미적 유사도)\n",
    "        target_plot_embedding = self.plot_embeddings[movie_idx].reshape(1, -1)\n",
    "        kobert_similarities = cosine_similarity(target_plot_embedding, self.plot_embeddings)[0]\n",
    "        kobert_similarities[kobert_similarities < 0] = 0\n",
    "        \n",
    "        # 2. 줄거리 TF-IDF 기반 유사도 (어휘적 유사도)\n",
    "        target_overview_vector = self.overview_matrix[movie_idx]\n",
    "        overview_similarities = cosine_similarity(target_overview_vector.reshape(1, -1), self.overview_matrix)[0]\n",
    "        overview_similarities[overview_similarities < 0] = 0\n",
    "        \n",
    "        # 3. 제목 유사도\n",
    "        target_title_vector = self.title_matrix[movie_idx]\n",
    "        title_similarities = cosine_similarity(target_title_vector, self.title_matrix)[0]\n",
    "        \n",
    "        # 4. 키워드 유사도\n",
    "        target_keyword_vector = self.keyword_matrix[movie_idx]\n",
    "        keyword_similarities = cosine_similarity(target_keyword_vector, self.keyword_matrix)[0]\n",
    "        \n",
    "        # 5. 고급 장르 유사도\n",
    "        target_genres = self.movie_data.iloc[movie_idx]['genres'].split(',') if self.movie_data.iloc[movie_idx]['genres'] else []\n",
    "        target_genres = [g.strip() for g in target_genres]\n",
    "        \n",
    "        genre_similarities = []\n",
    "        for i in range(len(self.movie_data)):\n",
    "            candidate_genres = self.movie_data.iloc[i]['genres'].split(',') if self.movie_data.iloc[i]['genres'] else []\n",
    "            candidate_genres = [g.strip() for g in candidate_genres]\n",
    "            \n",
    "            similarity = self.calculate_genre_similarity_advanced(target_genres, candidate_genres)\n",
    "            genre_similarities.append(similarity)\n",
    "        \n",
    "        genre_similarities = np.array(genre_similarities)\n",
    "        \n",
    "        # 6. 가중 평균으로 최종 유사도 계산\n",
    "        final_similarities = (\n",
    "            weights['kobert'] * kobert_similarities +\n",
    "            weights['overview_tfidf'] * overview_similarities +\n",
    "            weights['title'] * title_similarities +\n",
    "            weights['keywords'] * keyword_similarities +\n",
    "            weights['genre'] * genre_similarities\n",
    "        )\n",
    "        \n",
    "        return (final_similarities, kobert_similarities, overview_similarities, \n",
    "                title_similarities, keyword_similarities, genre_similarities)\n",
    "    \n",
    "    def adaptive_weights(self, movie_idx):\n",
    "        \"\"\"영화 특성에 따른 적응적 가중치 계산\"\"\"\n",
    "        movie_info = self.movie_data.iloc[movie_idx]\n",
    "        \n",
    "        # 1. 기본 가중치 설정 (총합 100%)\n",
    "        weights = {\n",
    "            'kobert': 0.15,\n",
    "            'overview_tfidf': 0.25,\n",
    "            'title': 0.05,  # 제목 유사도 문제 해결 전까지는 낮게 유지\n",
    "            'keywords': 0.25, # 키워드 중요성을 높임\n",
    "            'genre': 0.30   # 장르 중요성을 높임\n",
    "        }\n",
    "\n",
    "        # 모든 가중치 조정은 상대적으로 이루어지므로, 총합이 1이 되도록 조정하는 것이 중요합니다.\n",
    "        # 여기서는 편의상 절대값으로 더하고 빼지만, 실제로는 비율로 조정하거나, 마지막에 정규화해야 합니다.\n",
    "\n",
    "\n",
    "        # 2. 줄거리 길이에 따른 조정\n",
    "        overview_length = len(movie_info['overview']) if movie_info['overview'] else 0\n",
    "\n",
    "        if overview_length > 300:  # 긴 줄거리: 줄거리 관련 가중치 강화\n",
    "            weights['kobert'] += 0.03\n",
    "            weights['overview_tfidf'] += 0.05\n",
    "            weights['genre'] -= 0.04 # 상대적으로 장르 중요도 감소\n",
    "            weights['keywords'] -= 0.04\n",
    "        elif overview_length < 50:  # 짧은 줄거리: 제목/장르/키워드 강화, 줄거리 관련 약화\n",
    "            weights['title'] += 0.05 # 제목 유사도 개선 시 효과적\n",
    "            weights['genre'] += 0.05\n",
    "            weights['keywords'] += 0.05\n",
    "            weights['kobert'] -= 0.07 # KoBERT 낮춤\n",
    "            weights['overview_tfidf'] -= 0.08 # TF-IDF 낮춤\n",
    "\n",
    "        # 3. 장르 수에 따른 조정 (if-elif-else 구조 사용)\n",
    "        genre_count = len(movie_info['genres'].split(',')) if movie_info['genres'] else 0\n",
    "\n",
    "        if genre_count == 1:  # 단일 장르: 해당 장르의 특성을 강하게 반영\n",
    "            weights['genre'] += 0.10\n",
    "            weights['overview_tfidf'] -= 0.05\n",
    "            weights['keywords'] -= 0.05\n",
    "            weights['kobert'] -= 0.02\n",
    "        elif genre_count > 2:  # 많은 장르: 특정 장르에 덜 치우치도록\n",
    "            weights['genre'] -= 0.03\n",
    "            weights['kobert'] += 0.03 # KoBERT 영향력을 다시 높여 전체 줄거리 문맥 반영\n",
    "        # else: (2개의 장르인 경우 기본 가중치 유지)\n",
    "\n",
    "        # 4. 특정 장르에 대한 조정 (가장 구체적인 조건부터 배치)\n",
    "        genres = movie_info['genres'].lower() if movie_info['genres'] else ''\n",
    "\n",
    "        # 스릴러와 드라마 조합 (기생충, 하녀 등)\n",
    "        if '드라마' in genres and '스릴러' in genres and '코미디' in genres: # 기생충 같은 경우\n",
    "            weights['genre'] += 0.15 # 장르 매우 중요\n",
    "            weights['keywords'] += 0.05\n",
    "            weights['kobert'] -= 0.05 # KoBERT 비중 감소\n",
    "        elif '드라마' in genres and '스릴러' in genres: # 일반적인 드라마/스릴러\n",
    "            weights['genre'] += 0.10\n",
    "            weights['keywords'] += 0.05\n",
    "            weights['overview_tfidf'] += 0.02 # 줄거리 핵심 단어 중요도도 높임\n",
    "        elif 'sf' in genres or '공포' in genres: # '괴물' 같은 경우\n",
    "            weights['genre'] += 0.15 # 장르 매우 중요\n",
    "            weights['keywords'] += 0.10 # SF/공포는 키워드가 중요 (괴물, 좀비 등)\n",
    "            weights['overview_tfidf'] += 0.05 # 줄거리 내 핵심 단어 중요\n",
    "            weights['kobert'] -= 0.10 # KoBERT 비중 대폭 감소\n",
    "        elif '액션' in genres:\n",
    "            weights['keywords'] += 0.05\n",
    "            weights['overview_tfidf'] += 0.05 # 액션은 줄거리 내 동작 묘사가 중요\n",
    "            weights['title'] -= 0.05 # 제목보다는 내용이 중요\n",
    "        elif '로맨스' in genres:\n",
    "            weights['kobert'] += 0.03 # 감성적인 줄거리 유사성 중요\n",
    "            weights['overview_tfidf'] += 0.03\n",
    "            weights['keywords'] -= 0.03\n",
    "            weights['genre'] -= 0.03 # 로맨스는 장르가 넓어질 수 있으므로\n",
    "        elif '코미디' in genres:\n",
    "            weights['kobert'] += 0.02 # 코미디도 줄거리의 뉘앙스가 중요\n",
    "            weights['genre'] += 0.05 # 코미디 장르의 특색\n",
    "            weights['keywords'] -= 0.02\n",
    "\n",
    "        # 음수 가중치 방지 및 최소값 설정 (선택 사항)\n",
    "        for key in weights:\n",
    "            if weights[key] < 0.01: # 최소 가중치 설정 (예: 1%)\n",
    "                weights[key] = 0.01\n",
    "\n",
    "        # 가중치 정규화\n",
    "        total_weight = sum(weights.values())\n",
    "        weights = {k: v/total_weight for k, v in weights.items()}\n",
    "        \n",
    "        return weights\n",
    "    \n",
    "    def recommend_movies(self, movie_title=None, movie_idx=None, top_n=10, weights=None, use_adaptive_weights=True):\n",
    "        \"\"\"영화 추천\"\"\"\n",
    "        \n",
    "        if movie_idx is None:\n",
    "            if movie_title is None:\n",
    "                raise ValueError(\"movie_title 또는 movie_idx 중 하나는 제공되어야 합니다.\")\n",
    "            \n",
    "            # 제목으로 인덱스 찾기\n",
    "            matches = self.movie_data[self.movie_data['title'].str.contains(movie_title, case=False, na=False)]\n",
    "            if matches.empty:\n",
    "                print(f\"'{movie_title}'과 일치하는 영화를 찾을 수 없습니다.\")\n",
    "                return None\n",
    "            \n",
    "            movie_idx = matches.index[0]\n",
    "            actual_title = matches.iloc[0]['title']\n",
    "        else:\n",
    "            actual_title = self.movie_data.iloc[movie_idx]['title']\n",
    "        \n",
    "        # 가중치 결정\n",
    "        if use_adaptive_weights:\n",
    "            weights = self.adaptive_weights(movie_idx)\n",
    "            print(f\"적응적 가중치 사용: {weights}\")\n",
    "        elif weights is None:\n",
    "            weights = {\n",
    "                'kobert': 0.15,\n",
    "                'overview_tfidf': 0.35,\n",
    "                'title': 0.10,\n",
    "                'keywords': 0.25,\n",
    "                'genre': 0.15\n",
    "            }\n",
    "        \n",
    "        print(f\"\\n기준 영화: {actual_title}\")\n",
    "        print(f\"장르: {self.movie_data.iloc[movie_idx]['genres']}\")\n",
    "        print(f\"줄거리: {self.movie_data.iloc[movie_idx]['overview'][:400]}...\")\n",
    "        print(f\"   키워드: {self.movie_data.iloc[movie_idx]['keywords']}\")\n",
    "        \n",
    "        # 유사도 계산\n",
    "        similarities = self.calculate_similarity_comprehensive(movie_idx, weights)\n",
    "        final_similarities = similarities[0]\n",
    "        \n",
    "        # 자기 자신 제외하고 상위 N개 추천\n",
    "        similar_indices = np.argsort(final_similarities)[::-1][1:top_n+1]\n",
    "        \n",
    "        # 추천 결과 생성\n",
    "        recommendations = []\n",
    "        for idx in similar_indices:\n",
    "            movie_info = {\n",
    "                'title': self.movie_data.iloc[idx]['title'],\n",
    "                'genres': self.movie_data.iloc[idx]['genres'],\n",
    "                'overview': self.movie_data.iloc[idx]['overview'],\n",
    "                'keywords': self.movie_data.iloc[idx]['keywords'],\n",
    "                'total_similarity': final_similarities[idx],\n",
    "                'kobert_similarity': similarities[1][idx],\n",
    "                'overview_tfidf_similarity': similarities[2][idx],\n",
    "                'title_similarity': similarities[3][idx],\n",
    "                'keyword_similarity': similarities[4][idx],\n",
    "                'genre_similarity': similarities[5][idx]\n",
    "            }\n",
    "            recommendations.append(movie_info)\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def display_recommendations(self, recommendations):\n",
    "        \"\"\"추천 결과 출력\"\"\"\n",
    "        if not recommendations:\n",
    "            print(\"추천할 영화가 없습니다.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n=== 추천 영화 TOP {len(recommendations)} ===\")\n",
    "        \n",
    "        for i, movie in enumerate(recommendations, 1):\n",
    "            print(f\"\\n{i}. {movie['title']}\")\n",
    "            print(f\"   장르: {movie['genres']}\")\n",
    "            print(f\"   총 유사도: {movie['total_similarity']:.3f}\")\n",
    "            print(f\"   세부 유사도:\")\n",
    "            print(f\"     - KoBERT: {movie['kobert_similarity']:.3f}\")\n",
    "            print(f\"     - 줄거리 TF-IDF: {movie['overview_tfidf_similarity']:.3f}\")\n",
    "            print(f\"     - 제목: {movie['title_similarity']:.3f}\")\n",
    "            print(f\"     - 키워드: {movie['keyword_similarity']:.3f}\")\n",
    "            print(f\"     - 장르: {movie['genre_similarity']:.3f}\")\n",
    "            print(f\"   키워드: {movie['keywords']}\")\n",
    "            print(f\"   줄거리: {movie['overview'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877843fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 파일 로드 완료: ./stopwords/git_stopwords.txt (595개)\n",
      "데이터 전처리 중...\n",
      "✅ 저장된 특성 데이터를 불러옵니다...\n",
      "✅ 모든 특성 데이터 로드 완료.\n",
      "=== 괴물 기반 추천 (적응적 가중치) ===\n",
      "적응적 가중치 사용: {'kobert': 0.09166666666666666, 'overview_tfidf': 0.3333333333333333, 'title': 0.08333333333333334, 'keywords': 0.21666666666666667, 'genre': 0.27499999999999997}\n",
      "\n",
      "기준 영화: 괴물\n",
      "장르: SF, 공포, 드라마\n",
      "줄거리: 아버지가 운영하는 한강매점, 늘어지게 낮잠 자던 강두는 우연히 특이한 광경을 목격하게 된다. 생전 보도 못한 무언가가 한강다리에 매달려 움직이는 것이다. 정체를 알 수 없는 괴물은 둔치 위로 올라와 사람들을 거침없이 깔아뭉개고, 무차별로 물어뜯기 시작한다. 순식간에 아수라장으로 돌변하는 한강변. 강두도 뒤늦게 딸 현서를 데리고 정신없이 도망가지만, 꼭 잡았던 현서의 손을 놓치고 만다. 하루아침에 집과 생계, 그리고 현서까지 모든 것을 잃게 된 강두 가족. 돈도 없고 빽도 없는 그들은 위험구역으로 선포된 한강 어딘가에 있을 현서를 찾아 나선다....\n",
      "   키워드: ['괴물', '강두', '매점', '낮잠', '광경', '생전']\n",
      "\n",
      "=== 추천 영화 TOP 8 ===\n",
      "\n",
      "1. 초능력자\n",
      "   장르: SF, 스릴러, 액션\n",
      "   총 유사도: 0.341\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.877\n",
      "     - 줄거리 TF-IDF: 0.342\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.446\n",
      "     - 장르: 0.180\n",
      "   키워드: ['싸움', '괴물', '초인', '규남', '사람', '작고', '외진']\n",
      "   줄거리: 규남이 일하는 작고 외진 전당포, ‘유토피아’. 돈을 훔치러 들어온 초인이 사람들을 조종하기 시작하지만 초인의 통제를 벗어나 누군가가 힘겹게 움직이기 시작한다. 그 주인공은 바로 ...\n",
      "\n",
      "2. 슈렉\n",
      "   장르: 가족, 모험, 애니메이션, 코미디, 판타지\n",
      "   총 유사도: 0.322\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.878\n",
      "     - 줄거리 TF-IDF: 0.275\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.654\n",
      "     - 장르: 0.028\n",
      "   키워드: ['괴물', '슈렉', '동화', '파콰드영주', '늪지', '진흙']\n",
      "   줄거리: 성 밖 늪지대에 사는 엄청나게 못생기고 무지무지 큰 괴물 슈렉. 지저분한 진흙으로 샤워를 즐기고 동화책은 화장실 휴지 삼아 쓰는 그는 혼자만의 시간을 즐긴다.  그러던 어느 날, ...\n",
      "\n",
      "3. 메간\n",
      "   장르: SF, 공포\n",
      "   총 유사도: 0.318\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.864\n",
      "     - 줄거리 TF-IDF: 0.331\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.000\n",
      "     - 장르: 0.467\n",
      "   키워드: ['엔지니어', '케이디', '로봇', '교통사고', '이자', '보호자']\n",
      "   줄거리: 교통사고로 부모를 잃고 혼자가 된 소녀 ‘케이디’. 로봇 엔지니어이자, ‘케이디’의 보호자가 된 ‘젬마’는 ‘케이디’를 안전하게 지켜야 하는 프로그램이 입력된 AI 로봇 ‘메간’을...\n",
      "\n",
      "4. 마담 뺑덕\n",
      "   장르: 드라마, 로맨스, 스릴러\n",
      "   총 유사도: 0.305\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.901\n",
      "     - 줄거리 TF-IDF: 0.499\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.000\n",
      "     - 장르: 0.203\n",
      "   키워드: ['사랑', '학규', '덕이', '모든', '사람', '불미']\n",
      "   줄거리: 불미스러운 오해에 휘말려, 지방 소도시 문화센터의 문학 강사로 내려온 교수 학규는 퇴락한 놀이공원의 매표소 직원으로, 고여있는 일상에 신물 난 처녀 덕이와 걷잡을 수 없는 사랑에 ...\n",
      "\n",
      "5. 월드워 Z\n",
      "   장르: SF, 공포, 스릴러, 액션\n",
      "   총 유사도: 0.286\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.788\n",
      "     - 줄거리 TF-IDF: 0.386\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.000\n",
      "     - 장르: 0.310\n",
      "   키워드: ['군인', '도시', '정체', '제리', '곳곳', '원인', '이변']\n",
      "   줄거리: 세계 곳곳에서 원인을 알 수 없는 이변이 일어나기 시작하고, 정체 불명의 존재들의 무차별적 공격으로 도시는 순식간에 아수라장으로 변한다. 군인 출신으로 전시 경험이 풍부하고 위기 ...\n",
      "\n",
      "6. 검은 땅의 소녀와\n",
      "   장르: 드라마\n",
      "   총 유사도: 0.283\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.905\n",
      "     - 줄거리 TF-IDF: 0.407\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.000\n",
      "     - 장르: 0.233\n",
      "   키워드: ['영림', '동구', '보상금', '용달차', '탄광']\n",
      "   줄거리: 강원도 탄광촌, 녹록치 않은 현실 속에서도 아버지와 두 아이는 희망을 잃지 않고 즐겁게 살아간다. 누가 봐도 쉽지 않은 조건이지만 아이들과 함께 어떻게든 생계를 꾸려가고자 하는 아...\n",
      "\n",
      "7. 원더랜드\n",
      "   장르: SF, 드라마\n",
      "   총 유사도: 0.280\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.870\n",
      "     - 줄거리 TF-IDF: 0.216\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.000\n",
      "     - 장르: 0.467\n",
      "   키워드: ['원더', '랜드', '복원', '서비스', '사람']\n",
      "   줄거리: 죽은 사람을 인공지능으로 복원하는 원더랜드 서비스가 일상이 된 세상, 어린 딸에게 자신의 죽음을 숨기기 위해 원더랜드 서비스를 의뢰한 바이리와 사고로 누워있는 남자친구 태주를 원더...\n",
      "\n",
      "8. 연가시\n",
      "   장르: 드라마, 스릴러\n",
      "   총 유사도: 0.275\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.904\n",
      "     - 줄거리 TF-IDF: 0.382\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.000\n",
      "     - 장르: 0.235\n",
      "   키워드: ['연가시', '감염', '발견', '재난', '고요한']\n",
      "   줄거리: 고요한 새벽녘 한강에 뼈와 살가죽만 남은 참혹한 몰골의 시체들이 떠오른다. 이를 비롯해 전국 방방곡곡의 하천에서 변사체들이 발견되기 시작하는데… 원인은 숙주인 인간의 뇌를 조종하여...\n",
      "\n",
      "=== 기생충 기반 추천 (적응적 가중치) ===\n",
      "적응적 가중치 사용: {'kobert': 0.1391304347826087, 'overview_tfidf': 0.30434782608695654, 'title': 0.08695652173913045, 'keywords': 0.18260869565217394, 'genre': 0.28695652173913044}\n",
      "\n",
      "기준 영화: 기생충\n",
      "장르: 드라마, 스릴러, 코미디\n",
      "줄거리: 전원 백수로 반지하에 살던 기택 가족은 서로 끈끈하지만 삶은 막막하기만 하다. 그러던 어느 날, 장남 기우에게 친구가 해외 유학 대신 명문대생 과외 자리를 제안한다. 위조된 서류로 부유한 IT 기업 CEO 박 사장 저택에 입성한 기우는 엄청난 재산과 안락한 삶에 매료된다. 대담한 계획을 세운 기우는 교묘한 술수를 써서 여동생 기정을 미술 과외 교사로, 아버지 기택을 운전기사로, 어머니 충숙을 가정부로 들인다. 마침내 기택 가족 모두가 박 사장네에 성공적으로 위장 취업하며, 박 사장네는 자신들도 모르는 사이 기택 가족에게 잠식당한다. 완벽하게 속았다고 생각하며 호화로운 저택의 삶을 만끽하던 어느 비 오던 밤, 박 사장네가 잠시 집을 비운 사이 기택 가족은 축배를 든다. 그때, 잊혀진 존재였던 전 가정부 문광이...\n",
      "   키워드: ['교사', '기택', '가족', '사장', '저택', '과외']\n",
      "\n",
      "=== 추천 영화 TOP 8 ===\n",
      "\n",
      "1. 하녀\n",
      "   장르: 드라마, 스릴러\n",
      "   총 유사도: 0.481\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.908\n",
      "     - 줄거리 TF-IDF: 0.483\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.291\n",
      "     - 장르: 0.537\n",
      "   키워드: ['저택', '하녀', '이혼', '식당', '상류층']\n",
      "   줄거리: 이혼 후 식당 일을 하면서도 해맑게 살아가던 은이는 자신에게는 까마득하게 높은 상류층 대저택의 하녀로 들어간다. 완벽한 주인집 남자 훈, 쌍둥이를 임신 중인 안주인 해라, 자신을 ...\n",
      "\n",
      "2. 7호실\n",
      "   장르: 스릴러, 코미디\n",
      "   총 유사도: 0.419\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.872\n",
      "     - 줄거리 TF-IDF: 0.203\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.489\n",
      "     - 장르: 0.512\n",
      "   키워드: ['태정', '호실', '사장', '학자금', '알바생']\n",
      "   줄거리: 서울의 망해가는 DVD방 사장 두식. 학자금 빚을 갚으려 DVD방에서 일하는 알바생 태정. 팔리지도 않던 가게에 기적처럼 매수자가 나타난 바로 그 때! 예상치 못한 사고가 일어나고...\n",
      "\n",
      "3. 붉은 가족\n",
      "   장르: 드라마\n",
      "   총 유사도: 0.414\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.894\n",
      "     - 줄거리 TF-IDF: 0.568\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.133\n",
      "     - 장르: 0.323\n",
      "   키워드: ['싸움', '작전', '가족', '진달래', '창수', '조국', '위해']\n",
      "   줄거리: 조국을 위해 가족으로 뭉친 ‘암호명: 진달래’.  사이 좋은 가족으로 위장한 ‘진달래’의 진짜 정체는 공화국의 뛰어난 혁명 전사이다.  철두철미한 작전 수행을 자랑하는 그들은 반역...\n",
      "\n",
      "4. 완득이\n",
      "   장르: 드라마, 코미디\n",
      "   총 유사도: 0.412\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.852\n",
      "     - 줄거리 TF-IDF: 0.368\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.159\n",
      "     - 장르: 0.532\n",
      "   키워드: ['싸움', '똥주', '완득이', '가족', '삼촌', '고등학생']\n",
      "   줄거리: 남들보다 키는 작지만 자신에게만은 누구보다 큰 존재인 아버지와 언제부터인가 가족이 되어버린 삼촌과 함께 사는 고등학생 완득이. 가난하고 불우한 가정환경에 공부도 못하는 문제아지만 ...\n",
      "\n",
      "5. 좋지 아니한가\n",
      "   장르: 드라마, 코미디\n",
      "   총 유사도: 0.412\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.906\n",
      "     - 줄거리 TF-IDF: 0.359\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.131\n",
      "     - 장르: 0.532\n",
      "   키워드: ['미스터리', '사랑', '가족', '심씨', '아빠', '일생', '최대']\n",
      "   줄거리: 고개 숙인 아빠. 허리띠 졸라 맨 엄마, 전생에 왕이었다고 믿는 아들, 존재자체가 미스터리한 딸, 그리고 묻어가는 백수 이모까지. 한 집에 모여 살지만 공통점이라곤 눈곱만치도 찾아...\n",
      "\n",
      "6. 고령화 가족\n",
      "   장르: 드라마, 코미디\n",
      "   총 유사도: 0.410\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.794\n",
      "     - 줄거리 TF-IDF: 0.384\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.165\n",
      "     - 장르: 0.532\n",
      "   키워드: ['결혼', '미연', '나이', '가족', '빈대', '첫째']\n",
      "   줄거리: 평화롭던 엄마 집에 나이 값 못하는 가족이 다시 모여들기 시작한다. 엄마 집에 빈대 붙어 사는 철없는 백수 첫째 한모, 흥행참패 영화감독 둘째 인모, 결혼만 세 번째인 뻔뻔한 로맨...\n",
      "\n",
      "7. 마부\n",
      "   장르: 드라마, 전쟁\n",
      "   총 유사도: 0.390\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.932\n",
      "     - 줄거리 TF-IDF: 0.453\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.326\n",
      "     - 장르: 0.220\n",
      "   키워드: ['마부', '장남', '가족', '삼은', '고등고시']\n",
      "   줄거리: 짐수레를 끄는 홀아비 마부인 춘삼은 고등고시를 공부하는 장남 수업과, 언어 장애 탓에 못된 남편에게 맞고 쫓겨 오기 일쑤인 맏딸 옥례, 가난한 집안 형편에 불만을 품고 신분 상승을...\n",
      "\n",
      "8. 도그데이즈\n",
      "   장르: 드라마, 코미디\n",
      "   총 유사도: 0.387\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.907\n",
      "     - 줄거리 TF-IDF: 0.355\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.000\n",
      "     - 장르: 0.532\n",
      "   키워드: ['민서', '진영', '반려견', '완다', '위해']\n",
      "   줄거리: 깔끔한 성격의 계획형 싱글남 민상. 영끌까지 모아 산 건물을 개똥밭으로 만드는 세입자 수의사 진영 때문에 매일 머리가 아프다. 오늘도 진영과 티격태격하던 민상은 동물병원에서 한 성...\n",
      "\n",
      "=== 어벤져스 기반 추천 (적응적 가중치) ===\n",
      "적응적 가중치 사용: {'kobert': 0.06666666666666667, 'overview_tfidf': 0.2916666666666667, 'title': 0.08333333333333334, 'keywords': 0.25000000000000006, 'genre': 0.30833333333333335}\n",
      "\n",
      "기준 영화: 어벤져스\n",
      "장르: SF, 모험, 액션\n",
      "줄거리: 에너지원 큐브를 이용한 적의 등장으로 인류가 위험에 처하자 국제평화유지기구인 쉴드의 국장 닉 퓨리는 어벤져스 작전을 위해 전 세계에 흩어져 있던 슈퍼히어로들을 찾아나선다. 아이언맨부터 토르, 헐크, 캡틴 아메리카는 물론, 쉴드의 요원인 블랙 위도우, 호크 아이까지, 최고의 슈퍼히어로들이 어벤져스의 멤버로 모이게 되지만, 각기 개성이 강한 이들의 만남은 예상치 못한 방향으로 흘러가는데......\n",
      "   키워드: ['작전', '쉴드', '어벤져스', '슈퍼히어로', '큐브', '이용']\n",
      "\n",
      "=== 추천 영화 TOP 8 ===\n",
      "\n",
      "1. 어벤져스: 엔드게임\n",
      "   장르: SF, 모험, 액션\n",
      "   총 유사도: 0.555\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.833\n",
      "     - 줄거리 TF-IDF: 0.412\n",
      "     - 제목: 0.539\n",
      "     - 키워드: 0.409\n",
      "     - 장르: 0.753\n",
      "   키워드: ['히어로', '우주', '어벤져스', '지구', '생존']\n",
      "   줄거리: 어벤져스의 패배 이후 지구는 초토화됐고 남은 절반의 사람들은 정신적 고통을 호소하며 하루하루를 근근이 버텨나간다. 와칸다에서 싸우다 생존한 히어로들과 우주의 타이탄 행성에서 싸우다...\n",
      "\n",
      "2. 어벤져스: 인피니티 워\n",
      "   장르: SF, 모험, 액션\n",
      "   총 유사도: 0.487\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.877\n",
      "     - 줄거리 TF-IDF: 0.520\n",
      "     - 제목: 0.539\n",
      "     - 키워드: 0.000\n",
      "     - 장르: 0.753\n",
      "   키워드: ['노스', '스톤', '위해', '지구', '블랙']\n",
      "   줄거리: 타노스는 6개의 인피니티 스톤을 획득해 신으로 군림하려 한다. 그것은 곧 인류의 절반을 학살해 우주의 균형을 맞추겠다는 뜻. 타노스는 닥터 스트레인지가 소유한 타임 스톤, 비전의 ...\n",
      "\n",
      "3. 썬더볼츠*\n",
      "   장르: SF, 모험, 액션\n",
      "   총 유사도: 0.481\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.688\n",
      "     - 줄거리 TF-IDF: 0.344\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.410\n",
      "     - 장르: 0.753\n",
      "   키워드: ['스파이', '살인', '어벤져스', '최대', '위협', '세상', '위해']\n",
      "   줄거리: 어벤져스가 사라진 후, 세계 최대의 위협과 마주한 세상을 구하기 위해 전직 스파이, 암살자, 살인 청부 업자 등 마블의 별난 놈들이 펼치는 예측불허 팀플레이를 담은 액션 블록버스터...\n",
      "\n",
      "4. 인셉션\n",
      "   장르: SF, 모험, 액션\n",
      "   총 유사도: 0.425\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.778\n",
      "     - 줄거리 TF-IDF: 0.322\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.186\n",
      "     - 장르: 0.753\n",
      "   키워드: ['작전', '사랑', '생각', '코브', '인셉션', '제안', '특수']\n",
      "   줄거리: 타인의 꿈에 들어가 생각을 훔치는 특수 보안요원 코브. 그를 이용해 라이벌 기업의 정보를 빼내고자 하는 사이토는 코브에게 생각을 훔치는 것이 아닌, 생각을 심는 ‘인셉션’ 작전을 ...\n",
      "\n",
      "5. 아이언맨 3\n",
      "   장르: SF, 모험, 액션\n",
      "   총 유사도: 0.389\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.849\n",
      "     - 줄거리 TF-IDF: 0.344\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.000\n",
      "     - 장르: 0.753\n",
      "   키워드: ['사랑', '수트', '아이언맨', '어벤저스', '일원', '활약']\n",
      "   줄거리: 어벤저스의 일원으로 활약한 뉴욕 사건 이후, 트라우마로 인해 영웅으로서의 삶에 회의를 느끼는 토니 스타크. 그가 혼란을 겪는 사이 최악의 테러리스트 만다린을 내세운 익스트리미스 집...\n",
      "\n",
      "6. 블랙 팬서\n",
      "   장르: SF, 모험, 액션\n",
      "   총 유사도: 0.389\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.828\n",
      "     - 줄거리 TF-IDF: 0.349\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.000\n",
      "     - 장르: 0.753\n",
      "   키워드: ['전쟁', '스파이', '연인', '와칸', '폭탄', '티찰라', '블랙', '팬서']\n",
      "   줄거리: 유엔 폭탄 테러로 아버지를 잃은 와칸다의 왕자 티찰라는 시빌 워 이후 고국 와칸다로 돌아가 왕좌에 오른다. 와칸다의 새로운 지도자 블랙팬서가 된 그는 옛 연인이자 와칸다의 스파이 ...\n",
      "\n",
      "7. 아이언맨 2\n",
      "   장르: SF, 모험, 액션\n",
      "   총 유사도: 0.385\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.855\n",
      "     - 줄거리 TF-IDF: 0.329\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.000\n",
      "     - 장르: 0.753\n",
      "   키워드: ['복수', '토니', '아이언맨', '수트', '무기', '기술']\n",
      "   줄거리: 세계 최강의 무기업체를 이끄는 CEO이자, 타고난 매력으로 화려한 삶을 살아가던 토니 스타크. 기자회견을 통해 자신이 아이언맨이라고 정체를 밝힌 이후, 정부로부터 아이언맨 수트를 ...\n",
      "\n",
      "8. 아이언맨\n",
      "   장르: SF, 모험, 액션\n",
      "   총 유사도: 0.381\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.800\n",
      "     - 줄거리 TF-IDF: 0.327\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.000\n",
      "     - 장르: 0.753\n",
      "   키워드: ['음모', '납치', '무기', '토니', '수트', '게릴라군', '최강']\n",
      "   줄거리: 천재적인 두뇌와 재능으로 세계 최강의 무기업체를 이끄는 CEO이자, 타고난 매력으로 셀러브리티 못지않은 화려한 삶을 살아가던 억만장자 토니 스타크. 아프가니스탄에서 자신이 개발한 ...\n",
      "\n",
      "=== 유열의 음악앨범 기반 추천 (적응적 가중치) ===\n",
      "적응적 가중치 사용: {'kobert': 0.18, 'overview_tfidf': 0.32999999999999996, 'title': 0.1, 'keywords': 0.17, 'genre': 0.22}\n",
      "\n",
      "기준 영화: 유열의 음악앨범\n",
      "장르: 드라마, 로맨스\n",
      "줄거리: 1994년 가수 유열이 라디오 DJ를 처음 진행하던 날, 엄마가 남겨준 빵집에서 일하던 미수는 우연히 찾아 온 현우를 만나 설레는 감정을 느끼게 되지만 뜻하지 않은 사건으로 인해 연락이 끊기게 된다. 다시 기적처럼 마주친 두 사람은 설렘과 애틋함 사이에서 마음을 키워 가지만 서로의 상황과 시간은 자꾸 어긋나기만 한다. 계속되는 엇갈림 속에서도 라디오 ‘유열의 음악앨범’과 함께 우연과 필연을 반복하는 두 사람… 함께 듣던 라디오처럼 그들은 서로의 주파수를 맞출 수 있을까?...\n",
      "   키워드: ['유열', '사람', '서로', '가수', '처음']\n",
      "\n",
      "=== 추천 영화 TOP 8 ===\n",
      "\n",
      "1. 우리들의 행복한 시간\n",
      "   장르: 드라마, 로맨스\n",
      "   총 유사도: 0.489\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.746\n",
      "     - 줄거리 TF-IDF: 0.387\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.292\n",
      "     - 장르: 0.805\n",
      "   키워드: ['사랑', '눈물', '서로', '사람', '상처', '겨울', '고모']\n",
      "   줄거리: 세 번째 자살도 실패한 그 해 겨울, 모니카 고모의 손에 이끌려 교도소에 갔다. 내키진 않았지만, 정신병원에서 요양하는 것보다는 나을 테니까. 독해 보이는 창백한 얼굴의 사형수. ...\n",
      "\n",
      "2. 노트북\n",
      "   장르: 드라마, 로맨스\n",
      "   총 유사도: 0.478\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.826\n",
      "     - 줄거리 TF-IDF: 0.369\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.181\n",
      "     - 장르: 0.805\n",
      "   키워드: ['이별', '첫사랑', '노아', '앨리', '보고', '속도', '서로']\n",
      "   줄거리: 17살, 노아는 밝고 순수한 앨리를 보고 첫눈에 반한다. 빠른 속도로 서로에게 빠져드는 둘. 그러나 이들 앞에 놓인 장벽에 막혀 이별하게 된다. 24살, 앨리는 우연히 신문에서 노...\n",
      "\n",
      "3. 오래된 정원\n",
      "   장르: 드라마, 로맨스\n",
      "   총 유사도: 0.469\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.728\n",
      "     - 줄거리 TF-IDF: 0.431\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.108\n",
      "     - 장르: 0.805\n",
      "   키워드: ['갈등', '한윤희', '감옥', '지난', '사람', '생활']\n",
      "   줄거리: 80년대 군부독재에 반대하다가 젊음을 온통 감옥에서 보낸 현우(지진희 분). 17년이 지난 눈 내리는 어느 겨울, 교도소를 나선다. 변해 버린 가족과 서울풍경, 핸드폰이란 물건까지...\n",
      "\n",
      "4. 통증\n",
      "   장르: 드라마, 로맨스\n",
      "   총 유사도: 0.467\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.729\n",
      "     - 줄거리 TF-IDF: 0.248\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.451\n",
      "     - 장르: 0.805\n",
      "   키워드: ['통증', '남순', '사고', '고통', '처음']\n",
      "   줄거리: 어린 시절 자동차 사고로 가족을 잃은 죄책감과 그 사고로 인한 후천적인 후유증으로  통증을 느낄 수 없게 된 남자, 남순. 고통을 느낄 수 없는 탓에 무미건조한 삶을 살아가던 어느...\n",
      "\n",
      "5. 연애소설\n",
      "   장르: 드라마, 로맨스\n",
      "   총 유사도: 0.464\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.781\n",
      "     - 줄거리 TF-IDF: 0.385\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.112\n",
      "     - 장르: 0.805\n",
      "   키워드: ['사랑', '우정', '경희', '사람', '발신', '사진', '차태현']\n",
      "   줄거리: 어느 날, 지환(차태현 분)의 카메라 속으로 불쑥 수인(손예진 분)과 경희(이은주 분)가 들어온다. 닮은 듯 다른 두 사람, 수인과 경희는 둘도 없는 친구 사이. 수인에게 첫 눈에...\n",
      "\n",
      "6. 풀잎들\n",
      "   장르: 드라마\n",
      "   총 유사도: 0.462\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.789\n",
      "     - 줄거리 TF-IDF: 0.373\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.572\n",
      "     - 장르: 0.455\n",
      "   키워드: ['커피집', '사람', '서로', '골목', '여기저기']\n",
      "   줄거리: 커피집이 있을 것 같지 않은 골목 안으로 커피집이 있고 사람들이 커피집 안 여기저기에 앉아 얘기들을 하고 있습니다. 밖에는 건너편 슈퍼 아줌마가 심어 놓은 몇 가지 종류의 야채의 ...\n",
      "\n",
      "7. 50가지 그림자: 해방\n",
      "   장르: 드라마, 로맨스\n",
      "   총 유사도: 0.462\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.849\n",
      "     - 줄거리 TF-IDF: 0.268\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.256\n",
      "     - 장르: 0.805\n",
      "   키워드: ['그레이', '아나스타샤', '모든', '과거', '서로']\n",
      "   줄거리: 모든 과거를 잊고 서로에게 더 깊게 빠져든 ‘크리스찬 그레이’와 ‘아나스타샤’.  그레이의 독특한 취향으로 시작된 이 비밀스러운 관계는  더 큰 자극을 원하는 아나스타샤로 인해 역...\n",
      "\n",
      "8. 봄날은 간다\n",
      "   장르: 드라마, 로맨스\n",
      "   총 유사도: 0.458\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.613\n",
      "     - 줄거리 TF-IDF: 0.452\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.128\n",
      "     - 장르: 0.805\n",
      "   키워드: ['사랑', '엔지니어', '사람', '겨울', '사운드', '유지태', '치매']\n",
      "   줄거리: 사운드 엔지니어 상우(유지태)는 치매에 걸린 할머니(백성희)와 젊은 시절 상처한 한 아버지(박인환), 고모(신신애)와 함께 살고 있다. 어느 겨울 그는 지방 방송국 라디오 PD 은...\n",
      "\n",
      "=== 완벽한 타인 기반 추천 (적응적 가중치) ===\n",
      "적응적 가중치 사용: {'kobert': 0.16190476190476188, 'overview_tfidf': 0.2857142857142857, 'title': 0.09523809523809523, 'keywords': 0.17142857142857143, 'genre': 0.2857142857142857}\n",
      "\n",
      "기준 영화: 완벽한 타인\n",
      "장르: 드라마, 코미디\n",
      "줄거리: 우리 게임 한 번 해볼까? 다들 핸드폰 올려봐.  저녁 먹는 동안 오는 모든 걸 공유하는 거야.  전화, 문자, 카톡, 이메일 할 것 없이 싹!  오랜만의 커플 모임에서 한 명이 게임을 제안한다. 바로 각자의 핸드폰을 테이블 위에 올려두고 통화 내용부터 문자와 이메일까지 모두 공유하자고 한 것. 흔쾌히 게임을 시작하게 된 이들의 비밀이 핸드폰을 통해 들통나면서 처음 게임을 제안했던 것과는 전혀 다른 상상치 못한 결말로 흘러가는데......\n",
      "   키워드: ['게임', '핸드폰', '공유', '문자', '이메일']\n",
      "\n",
      "=== 추천 영화 TOP 8 ===\n",
      "\n",
      "1. 십개월의 미래\n",
      "   장르: 드라마, 코미디\n",
      "   총 유사도: 0.498\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.853\n",
      "     - 줄거리 TF-IDF: 0.306\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.322\n",
      "     - 장르: 0.760\n",
      "   키워드: ['배신', '결혼', '미래', '출산', '스물', '컴퓨터', '게임']\n",
      "   줄거리: 스물아홉의 컴퓨터 게임 개발자 미래가 임신 사실을 알게 된 뒤부터 출산 때까지의 과정을 그린다. 미래는 시간이 지나면서 자신을 둘러싼 환경이 얼마나 출산에 비협조적인지 깨닫게 되는...\n",
      "\n",
      "2. 후아유\n",
      "   장르: 로맨스, 코미디\n",
      "   총 유사도: 0.476\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.846\n",
      "     - 줄거리 TF-IDF: 0.434\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.667\n",
      "     - 장르: 0.353\n",
      "   키워드: ['멜로', '게임', '인주', '후아유', '형태', '수족관']\n",
      "   줄거리: 2년 동안 준비해온 채팅게임 '후아유'의 기획자 지형태(조승우)는 게임의 오픈을 앞두고 테스터들의 반응을 살피며 노심초사 하던 중 게임 게시판에서 '후아유'를 비방하는 ID 별이의...\n",
      "\n",
      "3. 마이 올드 애스\n",
      "   장르: 드라마, 코미디\n",
      "   총 유사도: 0.469\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.881\n",
      "     - 줄거리 TF-IDF: 0.381\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.000\n",
      "     - 장르: 0.760\n",
      "   키워드: ['사랑', '농담', '인생', '엘리엇', '생일', '버섯', '환각', '경험']\n",
      "   줄거리: 18번째 생일에 버섯 환각을 경험한 자유분방한 엘리엇은 농담을 일삼는 39세의 자신과 마주하게 된다. 하지만 나이 든 ‘자기 자신’이 어린 엘리엇에게 무엇을 해야 하고 하지 말아야...\n",
      "\n",
      "4. 그것만이 내 세상\n",
      "   장르: 드라마, 코미디\n",
      "   총 유사도: 0.465\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.832\n",
      "     - 줄거리 TF-IDF: 0.394\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.000\n",
      "     - 장르: 0.760\n",
      "   키워드: ['동생', '진태', '웰터급', '동양', '챔피언']\n",
      "   줄거리: 한때는 WBC 웰터급 동양 챔피언이었지만  지금은 오갈 데 없어진 한물간 전직 복서 조하. 우연히 17년 만에 헤어진 엄마 인숙과 재회하고, 숙식을 해결하기 위해 따라간 집에서  ...\n",
      "\n",
      "5. 싱크홀\n",
      "   장르: 드라마, 코미디\n",
      "   총 유사도: 0.440\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.882\n",
      "     - 줄거리 TF-IDF: 0.280\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.000\n",
      "     - 장르: 0.760\n",
      "   키워드: ['직장', '마련', '가장', '첫날', '프로', '참견']\n",
      "   줄거리: 서울 입성과 함께 내 집 마련의 꿈을 이룬 가장 동원은 이사 첫날부터 프로 참견러 만수와 사사건건 부딪힌다. 동원은 자가취득을 기념하며 직장 동료들을 집들이에 초대하지만 행복한 단...\n",
      "\n",
      "6. 칠수와 만수\n",
      "   장르: 드라마, 코미디\n",
      "   총 유사도: 0.436\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.797\n",
      "     - 줄거리 TF-IDF: 0.314\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.000\n",
      "     - 장르: 0.760\n",
      "   키워드: ['경찰', '연애', '기자', '만수', '누나', '옥상', '철탑', '세상']\n",
      "   줄거리: 그림에 소질이 있는 동두천 출신의 칠수(박중훈)는 미국에 사는 누나의 초청장을 기다리다가 생계 수단인 극장 미술부를 그만두고, 장기 복역 중인 아버지로 인해 연좌제로 고통받는 만수...\n",
      "\n",
      "7. 품행제로\n",
      "   장르: 드라마, 로맨스, 코미디\n",
      "   총 유사도: 0.430\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.832\n",
      "     - 줄거리 TF-IDF: 0.468\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.000\n",
      "     - 장르: 0.567\n",
      "   키워드: ['학교', '위해', '중필', '고의', '고단', '조무래기']\n",
      "   줄거리: 문덕고의 캡짱인 박중필의 하루는 무척 고단하다. 일단 학교 조무래기들의 기대에 부응하기 위해 호시탐탐 그의 자리를 노리고 있을 무리들과 겨뤄 심심챦게 얘깃거리를 제공해야 하고, 젊...\n",
      "\n",
      "8. 해치지않아\n",
      "   장르: 드라마, 코미디\n",
      "   총 유사도: 0.429\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.795\n",
      "     - 줄거리 TF-IDF: 0.290\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.000\n",
      "     - 장르: 0.760\n",
      "   키워드: ['변호사', '동산', '파크', '동물원', '동물', '북극곰']\n",
      "   줄거리: 생계형 수습 변호사 태수에게 찾아온 일생일대의 기회, 위기의 동물원 동산파크를 구하라! 동산파크의 새 원장이 된 그는 손님은커녕 동물조차 없는 동물원을 살리기 위해 직원들에게 동물...\n"
     ]
    }
   ],
   "source": [
    "# 사용 예시\n",
    "def create_extended_sample_data():\n",
    "    # movie_data.csv 파일을 불러와서 DataFrame 반환\n",
    "    df = pd.read_csv('../data_processing/movie_data.csv', encoding='utf-8-sig')\n",
    "    return df\n",
    "\n",
    "# 실행 예시\n",
    "if __name__ == \"__main__\":\n",
    "    # 확장된 샘플 데이터 생성\n",
    "    movies_df = create_extended_sample_data()\n",
    "    \n",
    "    # 개선된 추천 시스템 초기화\n",
    "    recommender = ImprovedMovieRecommendationSystem()\n",
    "    \n",
    "    # 데이터 전처리\n",
    "    recommender.prepare_data(movies_df)\n",
    "    \n",
    "    # 적응적 가중치로 추천\n",
    "    print(\"=== 괴물 기반 추천 (적응적 가중치) ===\")\n",
    "    recommendations1 = recommender.recommend_movies(\n",
    "        movie_title='괴물',\n",
    "        top_n=8,\n",
    "        use_adaptive_weights=True\n",
    "    )\n",
    "    recommender.display_recommendations(recommendations1)\n",
    "    \n",
    "    # 다른 영화로 테스트\n",
    "    print(\"\\n=== 기생충 기반 추천 (적응적 가중치) ===\")\n",
    "    recommendations2 = recommender.recommend_movies(\n",
    "        movie_title='기생충',\n",
    "        top_n=8,\n",
    "        use_adaptive_weights=True\n",
    "    )\n",
    "    recommender.display_recommendations(recommendations2)\n",
    "\n",
    "    # 다른 영화로 테스트\n",
    "    print(\"\\n=== 어벤져스 기반 추천 (적응적 가중치) ===\")\n",
    "    recommendations3 = recommender.recommend_movies(\n",
    "        movie_title='어벤져스',\n",
    "        top_n=8,\n",
    "        use_adaptive_weights=True\n",
    "    )\n",
    "    recommender.display_recommendations(recommendations3)\n",
    "\n",
    "    print(\"\\n=== 유열의 음악앨범 기반 추천 (적응적 가중치) ===\")\n",
    "    recommendations4 = recommender.recommend_movies(\n",
    "        movie_title='유열의 음악앨범',\n",
    "        top_n=8,\n",
    "        use_adaptive_weights=True\n",
    "    )\n",
    "    recommender.display_recommendations(recommendations4)\n",
    "\n",
    "    print(\"\\n=== 완벽한 타인 기반 추천 (적응적 가중치) ===\")\n",
    "    recommendations5 = recommender.recommend_movies(\n",
    "        movie_title='완벽한 타인',\n",
    "        top_n=8,\n",
    "        use_adaptive_weights=True\n",
    "    )\n",
    "    recommender.display_recommendations(recommendations5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5386cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 추천 개선\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "import os, pickle, json\n",
    "from collections import Counter\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "class ImprovedMovieRecommendationSystem:\n",
    "    def __init__(self, stopword_files = None, cache_dir=\"./cached_features\"):\n",
    "        self.kobert_tokenizer = None\n",
    "        self.kobert_model = None\n",
    "        self.tfidf_title = None\n",
    "        self.tfidf_overview = None\n",
    "        self.tfidf_keywords = None\n",
    "        self.mlb_genre = None\n",
    "        self.movie_data = None\n",
    "        self.plot_embeddings = None\n",
    "        self.title_matrix = None\n",
    "        self.genre_matrix = None\n",
    "        self.keyword_matrix = None\n",
    "        self.overview_matrix = None\n",
    "        \n",
    "        self.cache_dir = cache_dir\n",
    "\n",
    "        # 캐시 디렉토리 생성\n",
    "        if not os.path.exists(self.cache_dir):\n",
    "            os.makedirs(self.cache_dir)\n",
    "            print(f\"캐시 디렉토리 생성: {self.cache_dir}\")\n",
    "\n",
    "        # 불용어 파일 리스트가 제공되면 로드, 아니면 기본 빈 set\n",
    "        if stopword_files is None:\n",
    "            # 기본 불용어 파일 (예시: 프로젝트 내에 git_stopwords.txt 하나만 있는 경우)\n",
    "            # 또는 비어있는 set으로 시작하여 불용어 처리를 하지 않을 수도 있습니다.\n",
    "            stopword_files = [\"git_stopwords.txt\"] # 기본 파일 경로 지정\n",
    "        \n",
    "        self.custom_stopwords = self.load_stopwords_from_files(stopword_files)\n",
    "        \n",
    "    def load_kobert_model(self):\n",
    "        \"\"\"KoBERT 모델 로드\"\"\"\n",
    "        print(\"KoBERT 모델 로딩 중...\")\n",
    "        model_name = \"monologg/kobert\"\n",
    "        self.kobert_model = AutoModel.from_pretrained(model_name)\n",
    "        self.kobert_tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "        self.kobert_model.eval()\n",
    "        print(\"KoBERT 모델 로드 완료\")\n",
    "\n",
    "    def enhanced_text_preprocessing(self, text):\n",
    "        \"\"\"텍스트 전처리 강화\"\"\"\n",
    "        if not text or pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        text = str(text)\n",
    "        \n",
    "        # 특수 문자 및 숫자 처리\n",
    "        text = re.sub(r'[^\\w\\s가-힣a-zA-Z0-9]', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        \n",
    "        return text.strip()\n",
    "\n",
    "    def extract_nouns_from_text(self, text, okt):\n",
    "        \"\"\"텍스트에서 명사 추출\"\"\"\n",
    "        if not text:\n",
    "            return []\n",
    "        \n",
    "        # 명사 추출\n",
    "        nouns = okt.nouns(text)\n",
    "        \n",
    "        # 단어 길이가 1 이하인 것 제거\n",
    "        filtered_nouns = [noun for noun in nouns if len(noun) > 1]\n",
    "        \n",
    "        return filtered_nouns\n",
    "    \n",
    "    def load_stopwords_from_files(self, stopword_files):\n",
    "        \"\"\"여러 불용어 파일을 로드하여 하나의 set으로 통합\"\"\"\n",
    "        combined_stopwords = set()\n",
    "        \n",
    "        base_dir = \"./stopwords/\"\n",
    "\n",
    "        for file_name in stopword_files:\n",
    "            file_path = os.path.join(base_dir, file_name)\n",
    "\n",
    "            if os.path.exists(file_path):\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        words = [line.strip() for line in f if line.strip()]\n",
    "                        combined_stopwords.update(words)\n",
    "                    print(f\"불용어 파일 로드 완료: {file_path} ({len(words)}개)\")\n",
    "                except Exception as e:\n",
    "                    print(f\"불용어 파일 로드 실패: {file_path} - {e}\")\n",
    "    \n",
    "        if not combined_stopwords: # 로드된 불용어가 없을 경우 (파일이 없거나 비어있을 때)\n",
    "            print(\"❗ 모든 불용어 파일을 로드할 수 없거나 파일이 비어 있어 기본 불용어를 사용합니다.\")\n",
    "            # 예비 불용어 리스트를 set으로 변환\n",
    "            return set(['하다', '있다', '없다', '되다', '이다', '것', '수', '점', '말', '안', '때', '등', '통해'])\n",
    "        \n",
    "        return combined_stopwords\n",
    "\n",
    "\n",
    "    def enhanced_text_preprocessing_token(self, text):\n",
    "        if pd.isna(text) or not text:\n",
    "            return \"\"\n",
    "\n",
    "        text = self.enhanced_text_preprocessing(text)\n",
    "        stopwords_pos = ['Josa', 'Eomi', 'Suffix', 'Punctuation'] \n",
    "        \n",
    "        tokens = self.okt.pos(text, norm=True, stem=True)\n",
    "        \n",
    "        filtered_tokens = []\n",
    "        for word, pos in tokens:\n",
    "            if pos not in stopwords_pos:\n",
    "                # 함수 내부에서 로드한 custom_stopwords 사용\n",
    "                if word not in self.custom_stopwords: \n",
    "                    filtered_tokens.append(word)\n",
    "        \n",
    "        return ' '.join(filtered_tokens)\n",
    "    \n",
    "    def extract_keywords(self, text):\n",
    "        \"\"\"텍스트에서 키워드 추출 (형태소 분석 + 불용어 제거 + 가중치 적용)\"\"\"\n",
    "        if not text or pd.isna(text):\n",
    "            return []\n",
    "        \n",
    "        # OKT 형태소 분석기 초기화 (클래스 변수로 관리하면 더 효율적)\n",
    "        if not hasattr(self, 'okt'):\n",
    "            self.okt = Okt()\n",
    "        \n",
    "        # 불용어 로드 (처음 한 번만 실행)\n",
    "        if not hasattr(self, 'stopwords'):\n",
    "            stopword_files = [\n",
    "                'common_name_stopwords.txt',\n",
    "                'korean_adverb_stopwords.txt', \n",
    "                'general_stopwords.txt',\n",
    "                'git_stopwords.txt'\n",
    "            ]\n",
    "            self.stopwords = self.load_stopwords_from_files(stopword_files)\n",
    "            print(f\"전체 불용어 개수: {len(self.stopwords)}\")\n",
    "        \n",
    "        # 한국어 영화 관련 키워드 패턴 (가중치 포함)\n",
    "        movie_keywords = {\n",
    "            # 장르 관련 (가중치 2)\n",
    "            'action': {\n",
    "                'weight': 2,\n",
    "                'keywords': [\n",
    "                    '액션', '전투', '싸움', '전쟁', '격투', '추격', '폭발', '총격',\n",
    "                    '무술', '카체이싱', '건파이트', '배틀', '액션스릴러', '느와르',\n",
    "                    '스파이', '첩보', '잠입', '미션', '작전', '복수', '정의', '위장'\n",
    "                ]\n",
    "            },\n",
    "            'romance': {\n",
    "                'weight': 2,\n",
    "                'keywords': [\n",
    "                    '사랑', '로맨스', '연인', '결혼', '연애', '첫사랑', '이별', '만남',\n",
    "                    '멜로', '러브스토리', '운명', '재회', '프로포즈', '웨딩', '데이트',\n",
    "                    '썸', '고백', '짝사랑', '원거리', '국제연애', '나이차', '사내연애'\n",
    "                ]\n",
    "            },\n",
    "            'comedy': {\n",
    "                'weight': 2,\n",
    "                'keywords': [\n",
    "                    '코미디', '웃음', '유머', '재미', '개그', '유쾌', '농담',\n",
    "                    '개그맨', '상황극', '슬랩스틱', '로맨틱코미디', '패밀리코미디',\n",
    "                    '블랙코미디', '풍자', '해학', '익살', '코믹', '유머러스'\n",
    "                ]\n",
    "            },\n",
    "            'horror': {\n",
    "                'weight': 2,\n",
    "                'keywords': [\n",
    "                    '공포', '호러', '무서운', '귀신', '좀비', '괴물', '악령',\n",
    "                    '사이코', '살인마', '연쇄살인', '초자연', '오컬트', '엑소시즘',\n",
    "                    '저주', '원혼', '귀신', '유령', '무덤', '폐가', '심령', '위험구역'\n",
    "                ]\n",
    "            },\n",
    "            'thriller': {\n",
    "                'weight': 2,\n",
    "                'keywords': [\n",
    "                    '스릴러', '긴장', '추적', '수사', '범죄', '살인', '미스터리',\n",
    "                    '서스펜스', '추리', '탐정', '형사', '검찰', '법정', '재판',\n",
    "                    '납치', '협박', '음모', '배신', '사기', '해킹', '첩보'\n",
    "                ]\n",
    "            },\n",
    "            'drama': {\n",
    "                'weight': 2,\n",
    "                'keywords': [\n",
    "                    '인간', '감동', '눈물', '인생', '성장'\n",
    "                ]\n",
    "            },\n",
    "            \n",
    "            # 테마/소재 관련 (가중치 1.5)\n",
    "            'theme': {\n",
    "                'weight': 1.5,\n",
    "                'keywords': [\n",
    "                    '복수', '정의', '우정', '배신', '희생',\n",
    "                    '성장', '자아실현', '꿈', '도전', '극복', '화해',\n",
    "                    '갈등', '대립', '협력', '경쟁', '성공', '실패'\n",
    "                ]\n",
    "            },\n",
    "            'emotion': {\n",
    "                'weight': 1.5,\n",
    "                'keywords': [\n",
    "                    '감동', '눈물', '슬픔', '기쁨', '행복', '분노',\n",
    "                    '절망', '희망', '사랑', '이별', '그리움', '향수',\n",
    "                    '외로움', '고독', '우울', '스트레스', '끔찍한'\n",
    "                ]\n",
    "            },\n",
    "            \n",
    "            # 배경/직업 관련 (가중치 1)\n",
    "            'profession': {\n",
    "                'weight': 1,\n",
    "                'keywords': [\n",
    "                    '의사', '변호사', '교사', '경찰', '소방관', '군인',\n",
    "                    '기자', '작가', '화가', '음악가', '요리사', '사업가',\n",
    "                    '정치인', '연예인', '운동선수', '과학자', '엔지니어'\n",
    "                ]\n",
    "            },\n",
    "            'background': {\n",
    "                'weight': 1,\n",
    "                'keywords': [\n",
    "                    '현대', '도시', '서울', '학교', '대학', '회사', '직장',\n",
    "                    '병원', '법원', '경찰서', '아파트', '카페'\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 1. 텍스트 전처리\n",
    "        preprocessed_text = self.enhanced_text_preprocessing(text)\n",
    "        \n",
    "        # 2. 형태소 분석으로 명사 추출\n",
    "        nouns = self.extract_nouns_from_text(preprocessed_text, self.okt)\n",
    "        \n",
    "        # 3. 불용어 제거\n",
    "        filtered_nouns = [noun for noun in nouns \n",
    "                        if noun not in self.stopwords]\n",
    "        \n",
    "        # 4. 명사 빈도 계산\n",
    "        noun_counts = Counter(filtered_nouns)\n",
    "        \n",
    "        # 5. 영화 키워드 매칭 및 가중치 적용\n",
    "        keyword_scores = {}\n",
    "        \n",
    "        for category, category_info in movie_keywords.items():\n",
    "            weight = category_info['weight']\n",
    "            keywords = category_info['keywords']\n",
    "            \n",
    "            for keyword in keywords:\n",
    "                # 키워드가 추출된 명사에 있는지 확인\n",
    "                if keyword in filtered_nouns:\n",
    "                    score = noun_counts[keyword] * weight\n",
    "                    if keyword in keyword_scores:\n",
    "                        keyword_scores[keyword] += score\n",
    "                    else:\n",
    "                        keyword_scores[keyword] = score\n",
    "        \n",
    "        # 6. 점수 기준으로 정렬하여 상위 키워드 반환\n",
    "        sorted_keywords = sorted(keyword_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # 상위 20개 키워드만 반환 (키워드만, 점수 제외)\n",
    "        top_keywords = [keyword for keyword, score in sorted_keywords[:20]]\n",
    "        \n",
    "        # 매칭되지 않은 중요 명사도 일부 포함 (빈도수 기준)\n",
    "        remaining_nouns = [noun for noun in noun_counts.most_common(10) \n",
    "                        if noun[0] not in top_keywords]\n",
    "        \n",
    "        # 최종 키워드 결합\n",
    "        final_keywords = top_keywords + [noun[0] for noun in remaining_nouns[:5]]\n",
    "        \n",
    "        return final_keywords[:25]  # 최대 25개 키워드 반환\n",
    "\n",
    "\n",
    "    def get_kobert_embedding(self, text):\n",
    "        \"\"\"KoBERT를 사용하여 텍스트 임베딩 생성\"\"\"\n",
    "        if not text or pd.isna(text):\n",
    "            return np.zeros(768)  # KoBERT 임베딩 차원\n",
    "        \n",
    "        # 텍스트 길이 제한 (KoBERT 최대 입력 길이 고려)\n",
    "        text = str(text)[:512]\n",
    "        \n",
    "        inputs = self.kobert_tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=512\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.kobert_model(**inputs)\n",
    "            # [CLS] 토큰의 임베딩 사용\n",
    "            embedding = outputs.last_hidden_state[:, 0, :].squeeze().detach().cpu().numpy()\n",
    "        \n",
    "        return embedding\n",
    "    \n",
    "    def calculate_genre_similarity_advanced(self, target_genres, candidate_genres):\n",
    "        \"\"\"고급 장르 유사도 계산\"\"\"\n",
    "        # 장르 간 유사도 매트릭스 (실제로는 더 정교하게 구성 가능)\n",
    "        with open(\"./genre_similarity_matrix_content.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "            genre_similarity_matrix = json.load(f)\n",
    "    \n",
    "        if not target_genres or not candidate_genres:\n",
    "            return 0.0\n",
    "        \n",
    "        # 직접 매치 점수\n",
    "        direct_match = len(set(target_genres) & set(candidate_genres)) / len(set(target_genres) | set(candidate_genres))\n",
    "        \n",
    "        # 간접 매치 점수\n",
    "        indirect_score = 0\n",
    "        for target_genre in target_genres:\n",
    "            for candidate_genre in candidate_genres:\n",
    "                if target_genre.lower() in genre_similarity_matrix:\n",
    "                    if candidate_genre.lower() in genre_similarity_matrix[target_genre.lower()]:\n",
    "                        indirect_score += genre_similarity_matrix[target_genre.lower()][candidate_genre.lower()]\n",
    "        \n",
    "        indirect_score = indirect_score / (len(target_genres) * len(candidate_genres)) if target_genres and candidate_genres else 0\n",
    "        \n",
    "        return 0.7 * direct_match + 0.3 * indirect_score\n",
    "    \n",
    "    def prepare_data(self, movies_df, force_recompute=False):\n",
    "        \"\"\"데이터 전처리 및 특성 추출\"\"\"\n",
    "        print(\"데이터 전처리 중...\")\n",
    "\n",
    "         # 캐시 파일 경로 정의\n",
    "        feature_objects_path = f\"{self.cache_dir}/feature_objects.pkl\"\n",
    "        feature_matrices_path = f\"{self.cache_dir}/feature_matrices.npz\"\n",
    "        movie_data_path = f\"{self.cache_dir}/movie_data.pkl\"\n",
    "        plot_embeddings_path = f\"{self.cache_dir}/plot_embeddings.npy\" # KoBERT 임베딩도 여기에 포함\n",
    "\n",
    "        # 캐시 존재 여부 확인 및 force_recompute에 따른 로드/재계산 결정\n",
    "        if not force_recompute and \\\n",
    "           os.path.exists(feature_objects_path) and \\\n",
    "           os.path.exists(feature_matrices_path) and \\\n",
    "           os.path.exists(movie_data_path) and \\\n",
    "           os.path.exists(plot_embeddings_path): # KoBERT 임베딩 파일도 확인\n",
    "            \n",
    "            print(\"✅ 저장된 특성 데이터를 불러옵니다...\")\n",
    "            try:\n",
    "                # 1. Feature objects (Vectorizer, SVD, MLB) 로드\n",
    "                with open(feature_objects_path, 'rb') as f:\n",
    "                    feature_objects = pickle.load(f)\n",
    "                    self.tfidf_title = feature_objects['tfidf_title']\n",
    "                    self.tfidf_overview = feature_objects['tfidf_overview']\n",
    "                    self.tfidf_keywords = feature_objects['tfidf_keywords']\n",
    "                    self.svd = feature_objects['svd']\n",
    "                    self.mlb_genre = feature_objects['mlb_genre']\n",
    "\n",
    "                # 2. Feature matrices (NumPy arrays) 로드\n",
    "                loaded_matrices = np.load(feature_matrices_path, allow_pickle=True)\n",
    "                self.title_matrix = loaded_matrices['title_matrix']\n",
    "                self.overview_matrix = loaded_matrices['overview_matrix']\n",
    "                self.keyword_matrix = loaded_matrices['keyword_matrix']\n",
    "                self.genre_matrix = loaded_matrices['genre_matrix']\n",
    "\n",
    "                # 3. KoBERT 임베딩 로드 (별도 파일로 관리)\n",
    "                self.plot_embeddings = np.load(plot_embeddings_path)\n",
    "\n",
    "                # 4. 영화 데이터 로드\n",
    "                self.movie_data = pd.read_pickle(movie_data_path)\n",
    "\n",
    "                print(\"✅ 모든 특성 데이터 로드 완료.\")\n",
    "                return\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"❌ 저장된 특성 데이터 로드 중 오류 발생: {e}. 데이터를 새로 계산합니다.\")\n",
    "                # 오류 발생 시 다시 계산하도록 플래그 설정\n",
    "                force_recompute = True # 에러 발생 시 재계산을 유도\n",
    "\n",
    "        # 캐시가 없거나, 강제로 재계산해야 하는 경우\n",
    "        print(\"🛠 데이터를 새로 전처리하고 특성을 추출합니다...\")\n",
    "        \n",
    "        # 필수 컬럼 확인\n",
    "        required_columns = ['title', 'overview', 'genres']\n",
    "        for col in required_columns:\n",
    "            if col not in movies_df.columns:\n",
    "                raise ValueError(f\"필수 컬럼 '{col}'이 데이터에 없습니다.\")\n",
    "        \n",
    "        # 결측값 처리\n",
    "        movies_df['title'] = movies_df['title'].fillna('')\n",
    "        movies_df['overview'] = movies_df['overview'].fillna('')\n",
    "        movies_df['genres'] = movies_df['genres'].fillna('')\n",
    "        \n",
    "        # 키워드 추출\n",
    "        print(\"키워드 추출 중...\")\n",
    "        movies_df['keywords'] = movies_df['overview'].apply(self.extract_keywords)\n",
    "        movies_df['keywords_text'] = movies_df['keywords'].apply(lambda x: ' '.join(x) if x else '')\n",
    "        \n",
    "        movies_df['title_text'] = movies_df['title'].apply(self.enhanced_text_preprocessing_token)\n",
    "        movies_df['overview_text'] = movies_df['overview'].apply(self.enhanced_text_preprocessing_token)\n",
    "\n",
    "        self.movie_data = movies_df.copy()\n",
    "        \n",
    "        # 1. 제목 TF-IDF 벡터화\n",
    "        print(\"제목 TF-IDF 벡터화 중...\")\n",
    "        self.tfidf_title = TfidfVectorizer(\n",
    "            max_features=5000,\n",
    "            stop_words=None,\n",
    "            ngram_range=(1, 2),\n",
    "            min_df=1\n",
    "        )\n",
    "        self.title_matrix = self.tfidf_title.fit_transform(movies_df['title_text'])\n",
    "\n",
    "        # 2. 줄거리 TF-IDF 벡터화 (형태소 분리 적용)    \n",
    "        self.tfidf_overview = TfidfVectorizer(\n",
    "            max_features=10000, \n",
    "            stop_words=None, \n",
    "            ngram_range=(1, 2), \n",
    "            min_df=1 \n",
    "        )\n",
    "        overview_tfidf_matrix = self.tfidf_overview.fit_transform(movies_df['overview_text'])\n",
    "        print(\"줄거리 TF-IDF 벡터화 완료.\")\n",
    "\n",
    "        # LSA (Truncated SVD)\n",
    "        self.svd = TruncatedSVD(n_components=100, random_state=42)\n",
    "        self.overview_matrix = self.svd.fit_transform(overview_tfidf_matrix)\n",
    "        \n",
    "        # 3. 키워드 TF-IDF 벡터화\n",
    "        print(\"키워드 TF-IDF 벡터화 중...\")\n",
    "        self.tfidf_keywords = TfidfVectorizer(\n",
    "            max_features=1000,\n",
    "            stop_words=None,\n",
    "            ngram_range=(1, 1),\n",
    "            min_df=3,  # 최소 2개 영화에서 나타나는 키워드만 사용\n",
    "            max_df=0.4,  # 40% 이상 영화에 나타나는 키워드는 제외\n",
    "        )\n",
    "        self.keyword_matrix = self.tfidf_keywords.fit_transform(movies_df['keywords_text'])\n",
    "        \n",
    "        # 4. 장르 처리\n",
    "        print(\"장르 처리 중...\")\n",
    "        genre_lists = []\n",
    "        for genres in movies_df['genres']:\n",
    "            if isinstance(genres, str) and genres:\n",
    "                genre_list = [g.strip() for g in genres.split(',')]\n",
    "                genre_lists.append(genre_list)\n",
    "            elif isinstance(genres, list):\n",
    "                genre_lists.append(genres)\n",
    "            else:\n",
    "                genre_lists.append([])\n",
    "        \n",
    "        self.mlb_genre = MultiLabelBinarizer()\n",
    "        self.genre_matrix = self.mlb_genre.fit_transform(genre_lists)\n",
    "\n",
    "        # 5. KoBERT 임베딩\n",
    "        print(\"🛠 줄거리 임베딩을 새로 생성합니다.\")\n",
    "        if self.kobert_model is None:\n",
    "            self.load_kobert_model()\n",
    "        \n",
    "        plot_embeddings = []\n",
    "        for i, overview in enumerate(movies_df['overview_text']):\n",
    "            if i % 50 == 0:\n",
    "                print(f\"임베딩 진행률: {i}/{len(movies_df)}\")\n",
    "            embedding = self.get_kobert_embedding(overview)\n",
    "            plot_embeddings.append(embedding)\n",
    "\n",
    "        self.plot_embeddings = np.array(plot_embeddings)\n",
    "        print(\"줄거리 임베딩 생성 완료.\")\n",
    "\n",
    "        self._save_all_features()\n",
    "        print(\"데이터 전처리 완료\")\n",
    "\n",
    "    def _save_all_features(self):\n",
    "        \"\"\"모든 특성을 한 번에 저장\"\"\"\n",
    "        if not os.path.exists(self.cache_dir):\n",
    "            os.makedirs(self.cache_dir)\n",
    "        \n",
    "        print(\"💾 모든 특성 데이터 저장 중...\")\n",
    "        \n",
    "        # 1. TF-IDF 벡터화 객체들 저장\n",
    "        feature_objects = {\n",
    "            'tfidf_title': self.tfidf_title,\n",
    "            'tfidf_overview': self.tfidf_overview,\n",
    "            'tfidf_keywords': self.tfidf_keywords,\n",
    "            'svd': self.svd,\n",
    "            'mlb_genre': self.mlb_genre\n",
    "        }\n",
    "        \n",
    "        # Ensure file exists before attempting to open, or handle errors\n",
    "        try:\n",
    "            with open(f\"{self.cache_dir}/feature_objects.pkl\", 'wb') as f:\n",
    "                pickle.dump(feature_objects, f)\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving feature objects: {e}\")\n",
    "            # Optionally, re-raise or handle more gracefully\n",
    "\n",
    "        # 2. 특성 행렬들 저장\n",
    "        # Scipy sparse matrix (CSR) toarray() to save as dense numpy array\n",
    "        # Check if matrices are sparse before converting\n",
    "        title_matrix_array = self.title_matrix.toarray() if hasattr(self.title_matrix, 'toarray') else self.title_matrix\n",
    "        keyword_matrix_array = self.keyword_matrix.toarray() if hasattr(self.keyword_matrix, 'toarray') else self.keyword_matrix\n",
    "        overview_matrix_array = self.overview_matrix if isinstance(self.overview_matrix, np.ndarray) else self.overview_matrix.toarray()\n",
    "\n",
    "\n",
    "        np.savez_compressed(f\"{self.cache_dir}/feature_matrices.npz\",\n",
    "                            title_matrix=title_matrix_array,\n",
    "                            overview_matrix=overview_matrix_array,\n",
    "                            keyword_matrix=keyword_matrix_array,\n",
    "                            genre_matrix=self.genre_matrix)\n",
    "        \n",
    "        # KoBERT 임베딩은 별도 파일로 저장\n",
    "        np.save(f\"{self.cache_dir}/plot_embeddings.npy\", self.plot_embeddings)\n",
    "\n",
    "        # 3. 영화 데이터 저장 (전처리된 컬럼 포함)\n",
    "        self.movie_data.to_pickle(f\"{self.cache_dir}/movie_data.pkl\")\n",
    "        \n",
    "        print(f\"✅ 모든 데이터가 {self.cache_dir}에 저장되었습니다.\")\n",
    "    \n",
    "    def calculate_similarity_comprehensive(self, movie_idx, weights):\n",
    "        \"\"\"포괄적인 유사도 계산\"\"\"\n",
    "        \n",
    "        # 1. KoBERT 임베딩 기반 유사도 (의미적 유사도)\n",
    "        target_plot_embedding = self.plot_embeddings[movie_idx].reshape(1, -1)\n",
    "        kobert_similarities = cosine_similarity(target_plot_embedding, self.plot_embeddings)[0]\n",
    "        kobert_similarities[kobert_similarities < 0] = 0\n",
    "        \n",
    "        # 2. 줄거리 TF-IDF 기반 유사도 (어휘적 유사도)\n",
    "        target_overview_vector = self.overview_matrix[movie_idx]\n",
    "        overview_similarities = cosine_similarity(target_overview_vector.reshape(1, -1), self.overview_matrix)[0]\n",
    "        overview_similarities[overview_similarities < 0] = 0\n",
    "        \n",
    "        # 3. 제목 유사도\n",
    "        target_title_vector = self.title_matrix[movie_idx]\n",
    "        title_similarities = cosine_similarity(target_title_vector.reshape(1, -1), self.title_matrix)[0]\n",
    "        \n",
    "        # 4. 키워드 유사도\n",
    "        target_keyword_vector = self.keyword_matrix[movie_idx]\n",
    "        keyword_similarities = cosine_similarity(target_keyword_vector.reshape(1, -1), self.keyword_matrix)[0]\n",
    "        \n",
    "        # 5. 장르 유사도\n",
    "        target_genres = self.movie_data.iloc[movie_idx]['genres'].split(',') if self.movie_data.iloc[movie_idx]['genres'] else []\n",
    "        target_genres = [g.strip() for g in target_genres]\n",
    "        \n",
    "        genre_similarities = []\n",
    "        for i in range(len(self.movie_data)):\n",
    "            candidate_genres = self.movie_data.iloc[i]['genres'].split(',') if self.movie_data.iloc[i]['genres'] else []\n",
    "            candidate_genres = [g.strip() for g in candidate_genres]\n",
    "            \n",
    "            similarity = self.calculate_genre_similarity_advanced(target_genres, candidate_genres)\n",
    "            genre_similarities.append(similarity)\n",
    "        \n",
    "        genre_similarities = np.array(genre_similarities)\n",
    "        \n",
    "        # 6. 가중 평균으로 최종 유사도 계산\n",
    "        final_similarities = (\n",
    "            weights['kobert'] * kobert_similarities +\n",
    "            weights['overview_tfidf'] * overview_similarities +\n",
    "            weights['title'] * title_similarities +\n",
    "            weights['keywords'] * keyword_similarities +\n",
    "            weights['genre'] * genre_similarities\n",
    "        )\n",
    "        \n",
    "        return (final_similarities, kobert_similarities, overview_similarities, \n",
    "                title_similarities, keyword_similarities, genre_similarities)\n",
    "    \n",
    "    def adaptive_weights(self, movie_idx):\n",
    "        \"\"\"영화 특성에 따른 적응적 가중치 계산\"\"\"\n",
    "        movie_info = self.movie_data.iloc[movie_idx]\n",
    "        \n",
    "        # 1. 기본 가중치 설정 (총합 100%)\n",
    "        weights = {\n",
    "            'kobert': 0.20,\n",
    "            'overview_tfidf': 0.35,\n",
    "            'title': 0.10,  # 제목 유사도 문제 해결 전까지는 낮게 유지\n",
    "            'keywords': 0.20, # 키워드 중요성을 높임\n",
    "            'genre': 0.25   # 장르 중요성을 높임\n",
    "        }\n",
    "\n",
    "        # 모든 가중치 조정은 상대적으로 이루어지므로, 총합이 1이 되도록 조정하는 것이 중요합니다.\n",
    "        # 여기서는 편의상 절대값으로 더하고 빼지만, 실제로는 비율로 조정하거나, 마지막에 정규화해야 합니다.\n",
    "\n",
    "\n",
    "        # 2. 줄거리 길이에 따른 조정\n",
    "        overview_length = len(movie_info['overview']) if movie_info['overview'] else 0\n",
    "\n",
    "        if overview_length > 300:  # 긴 줄거리: 줄거리 관련 가중치 강화\n",
    "            weights['kobert'] += 0.03\n",
    "            weights['overview_tfidf'] += 0.05\n",
    "            weights['genre'] -= 0.04 # 상대적으로 장르 중요도 감소\n",
    "            weights['keywords'] -= 0.04\n",
    "        elif overview_length < 50:  # 짧은 줄거리: 제목/장르/키워드 강화, 줄거리 관련 약화\n",
    "            weights['title'] += 0.05 # 제목 유사도 개선 시 효과적\n",
    "            weights['genre'] += 0.05\n",
    "            weights['keywords'] += 0.05\n",
    "            weights['kobert'] -= 0.07 # KoBERT 낮춤\n",
    "            weights['overview_tfidf'] -= 0.08 # TF-IDF 낮춤\n",
    "\n",
    "        # 3. 장르 수에 따른 조정 (if-elif-else 구조 사용)\n",
    "        genre_count = len(movie_info['genres'].split(',')) if movie_info['genres'] else 0\n",
    "\n",
    "        if genre_count == 1:  # 단일 장르: 해당 장르의 특성을 강하게 반영\n",
    "            weights['genre'] += 0.10\n",
    "            weights['overview_tfidf'] -= 0.05\n",
    "            weights['keywords'] -= 0.05\n",
    "            weights['kobert'] -= 0.02\n",
    "        elif genre_count > 3:  # 많은 장르: 특정 장르에 덜 치우치도록\n",
    "            weights['genre'] -= 0.03\n",
    "            weights['kobert'] += 0.03 # KoBERT 영향력을 다시 높여 전체 줄거리 문맥 반영\n",
    "        # else: (2개의 장르인 경우 기본 가중치 유지)\n",
    "\n",
    "        # 4. 특정 장르에 대한 조정 (가장 구체적인 조건부터 배치)\n",
    "        genres = movie_info['genres'].lower() if movie_info['genres'] else ''\n",
    "\n",
    "        # 스릴러와 드라마 조합 (기생충, 하녀 등)\n",
    "        if '드라마' in genres and '스릴러' in genres and '코미디' in genres: # 기생충 같은 경우\n",
    "            weights['genre'] += 0.15 # 장르 매우 중요\n",
    "            weights['keywords'] += 0.05\n",
    "            weights['kobert'] -= 0.05 # KoBERT 비중 감소\n",
    "        elif '드라마' in genres and '스릴러' in genres: # 일반적인 드라마/스릴러\n",
    "            weights['genre'] += 0.10\n",
    "            weights['keywords'] += 0.05\n",
    "            weights['overview_tfidf'] += 0.02 # 줄거리 핵심 단어 중요도도 높임\n",
    "        elif 'sf' in genres or '공포' in genres: # '괴물' 같은 경우\n",
    "            weights['genre'] += 0.15 # 장르 매우 중요\n",
    "            weights['keywords'] += 0.10 # SF/공포는 키워드가 중요 (괴물, 좀비 등)\n",
    "            weights['overview_tfidf'] += 0.05 # 줄거리 내 핵심 단어 중요\n",
    "            weights['kobert'] -= 0.10 # KoBERT 비중 대폭 감소\n",
    "        elif '액션' in genres:\n",
    "            weights['keywords'] += 0.05\n",
    "            weights['overview_tfidf'] += 0.05 # 액션은 줄거리 내 동작 묘사가 중요\n",
    "            weights['title'] -= 0.05 # 제목보다는 내용이 중요\n",
    "        elif '로맨스' in genres:\n",
    "            weights['kobert'] += 0.03 # 감성적인 줄거리 유사성 중요\n",
    "            weights['overview_tfidf'] += 0.03\n",
    "            weights['keywords'] -= 0.03\n",
    "            weights['genre'] -= 0.03 # 로맨스는 장르가 넓어질 수 있으므로\n",
    "        elif '코미디' in genres:\n",
    "            weights['kobert'] += 0.02 # 코미디도 줄거리의 뉘앙스가 중요\n",
    "            weights['genre'] += 0.05 # 코미디 장르의 특색\n",
    "            weights['keywords'] -= 0.02\n",
    "\n",
    "        # 음수 가중치 방지 및 최소값 설정 (선택 사항)\n",
    "        for key in weights:\n",
    "            if weights[key] < 0.01: # 최소 가중치 설정 (예: 1%)\n",
    "                weights[key] = 0.01\n",
    "\n",
    "        # 가중치 정규화\n",
    "        total_weight = sum(weights.values())\n",
    "        weights = {k: v/total_weight for k, v in weights.items()}\n",
    "        \n",
    "        return weights\n",
    "    \n",
    "    def recommend_movies(self, movie_title=None, movie_idx=None, top_n=10, weights=None, use_adaptive_weights=True):\n",
    "        \"\"\"영화 추천\"\"\"\n",
    "        \n",
    "        if movie_idx is None:\n",
    "            if movie_title is None:\n",
    "                raise ValueError(\"movie_title 또는 movie_idx 중 하나는 제공되어야 합니다.\")\n",
    "            \n",
    "            # 제목으로 인덱스 찾기\n",
    "            matches = self.movie_data[self.movie_data['title'].str.contains(movie_title, case=False, na=False)]\n",
    "            if matches.empty:\n",
    "                print(f\"'{movie_title}'과 일치하는 영화를 찾을 수 없습니다.\")\n",
    "                return None\n",
    "            \n",
    "            movie_idx = matches.index[0]\n",
    "            actual_title = matches.iloc[0]['title']\n",
    "        else:\n",
    "            actual_title = self.movie_data.iloc[movie_idx]['title']\n",
    "        \n",
    "        # 가중치 결정\n",
    "        if use_adaptive_weights:\n",
    "            weights = self.adaptive_weights(movie_idx)\n",
    "            print(f\"적응적 가중치 사용: {weights}\")\n",
    "        elif weights is None:\n",
    "            weights = {\n",
    "                'kobert': 0.15,\n",
    "                'overview_tfidf': 0.35,\n",
    "                'title': 0.10,\n",
    "                'keywords': 0.25,\n",
    "                'genre': 0.15\n",
    "            }\n",
    "        \n",
    "        print(f\"\\n기준 영화: {actual_title}\")\n",
    "        print(f\"장르: {self.movie_data.iloc[movie_idx]['genres']}\")\n",
    "        print(f\"줄거리: {self.movie_data.iloc[movie_idx]['overview'][:400]}...\")\n",
    "        print(f\"   키워드: {self.movie_data.iloc[movie_idx]['keywords']}\")\n",
    "        \n",
    "        # 유사도 계산\n",
    "        similarities = self.calculate_similarity_comprehensive(movie_idx, weights)\n",
    "        final_similarities = similarities[0]\n",
    "        \n",
    "        # 자기 자신 제외하고 상위 N개 추천\n",
    "        similar_indices = np.argsort(final_similarities)[::-1][1:top_n+1]\n",
    "        \n",
    "        # 추천 결과 생성\n",
    "        recommendations = []\n",
    "        for idx in similar_indices:\n",
    "            movie_info = {\n",
    "                'title': self.movie_data.iloc[idx]['title'],\n",
    "                'genres': self.movie_data.iloc[idx]['genres'],\n",
    "                'overview': self.movie_data.iloc[idx]['overview'],\n",
    "                'keywords': self.movie_data.iloc[idx]['keywords'],\n",
    "                'total_similarity': final_similarities[idx],\n",
    "                'kobert_similarity': similarities[1][idx],\n",
    "                'overview_tfidf_similarity': similarities[2][idx],\n",
    "                'title_similarity': similarities[3][idx],\n",
    "                'keyword_similarity': similarities[4][idx],\n",
    "                'genre_similarity': similarities[5][idx]\n",
    "            }\n",
    "            recommendations.append(movie_info)\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def display_recommendations(self, recommendations):\n",
    "        \"\"\"추천 결과 출력\"\"\"\n",
    "        if not recommendations:\n",
    "            print(\"추천할 영화가 없습니다.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n=== 추천 영화 TOP {len(recommendations)} ===\")\n",
    "        \n",
    "        for i, movie in enumerate(recommendations, 1):\n",
    "            print(f\"\\n{i}. {movie['title']}\")\n",
    "            print(f\"   장르: {movie['genres']}\")\n",
    "            print(f\"   총 유사도: {movie['total_similarity']:.3f}\")\n",
    "            print(f\"   세부 유사도:\")\n",
    "            print(f\"     - KoBERT: {movie['kobert_similarity']:.3f}\")\n",
    "            print(f\"     - 줄거리 TF-IDF: {movie['overview_tfidf_similarity']:.3f}\")\n",
    "            print(f\"     - 제목: {movie['title_similarity']:.3f}\")\n",
    "            print(f\"     - 키워드: {movie['keyword_similarity']:.3f}\")\n",
    "            print(f\"     - 장르: {movie['genre_similarity']:.3f}\")\n",
    "            print(f\"   키워드: {movie['keywords']}\")\n",
    "            print(f\"   줄거리: {movie['overview'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1432ba8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 파일 로드 완료: ./stopwords/git_stopwords.txt (595개)\n",
      "데이터 전처리 중...\n",
      "✅ 저장된 특성 데이터를 불러옵니다...\n",
      "✅ 모든 특성 데이터 로드 완료.\n",
      "=== 어바웃 타임 기반 추천 (적응적 가중치) ===\n",
      "적응적 가중치 사용: {'kobert': 0.1739130434782609, 'overview_tfidf': 0.34782608695652173, 'title': 0.04347826086956522, 'keywords': 0.2173913043478261, 'genre': 0.2173913043478261}\n",
      "\n",
      "기준 영화: 유희왕 듀얼몬스터즈\n",
      "장르: 애니메이션, 액션&모험\n",
      "줄거리: 게임의 역사, 그것은 지금으로부터 5천년 전, 고대 이집트까지 거슬러 올라간다.\n",
      "\n",
      "고대에 행해진 게임은 인간이나 왕의 미래를 예언하고 운명을 결정하는 마술적인 의식이었다. 그것들은 '어둠의 게임'이라 불렀다.\n",
      "\n",
      "그리고, 지금 천년 퍼즐을 풀고 어둠의 게임을 계승한 소년이 있었으니...\n",
      "\n",
      "빛과 어둠, 두 개의 마음을 가진 소년. 사람들은 그를 유희왕이라 부른다....\n",
      "   키워드: ['게임', '어둠', '지금', '고대', '소년']\n",
      "\n",
      "=== 추천 영화 TOP 8 ===\n",
      "\n",
      "1. 소드 아트 온라인\n",
      "   장르: SF&판타지, 애니메이션, 액션&모험\n",
      "   총 유사도: 0.521\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.810\n",
      "     - 줄거리 TF-IDF: 0.672\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.206\n",
      "     - 장르: 0.467\n",
      "   키워드: ['게임', '온라인', '플레이어', '가상', '소드']\n",
      "   줄거리: 2022년. 인류는 마침내 완전한 가상 공간을 실현했다. 모든 게이머가 꿈꿔왔던 VRMMORPG (가상 대규모 온라인 롤 플레잉 게임)  \"소드 아트 온라인\" 이 정식 가동을 시작...\n",
      "\n",
      "2. 주먹왕 랄프\n",
      "   장르: 가족, 모험, 애니메이션, 코미디\n",
      "   총 유사도: 0.481\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.702\n",
      "     - 줄거리 TF-IDF: 0.720\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.257\n",
      "     - 장르: 0.243\n",
      "   키워드: ['게임', '랄프', '펠릭스', '건물', '부수']\n",
      "   줄거리: 8비트 게임 ‘다고쳐 펠릭스’에서 건물을 부수는 악당 주먹왕 랄프. 30년째 매일같이 건물을 부수며 직업에 충실해왔지만, 악당이라는 이유로 누구도 그를 좋아하지 않는다. 모두에게 ...\n",
      "\n",
      "3. 노 게임 노 라이프\n",
      "   장르: SF&판타지, 애니메이션, 액션&모험, 코미디\n",
      "   총 유사도: 0.476\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.825\n",
      "     - 줄거리 TF-IDF: 0.612\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.178\n",
      "     - 장르: 0.372\n",
      "   키워드: ['전쟁', '도시', '남매', '게임', '시로', '폐인', '인터넷']\n",
      "   줄거리: 인터넷에서는 도시전설이라는 이야기마저 떠도는 천재 게이머 남매, 소라(空)와 시로(白). ID가 항상 공란인 관계로 통칭 공백이라고 불리는 이 남매는 세상을 쓰레기 게임이라고 부르...\n",
      "\n",
      "4. 데스 퍼레이드\n",
      "   장르: 드라마, 미스터리, 애니메이션\n",
      "   총 유사도: 0.462\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.803\n",
      "     - 줄거리 TF-IDF: 0.689\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.189\n",
      "     - 장르: 0.190\n",
      "   키워드: ['재판', '데킴', '손님', '게임', '명의', '사후']\n",
      "   줄거리: 사후, 인간의 영혼이 모이는 이상한 Bar, 퀸 데킴. 이곳에는 같은 시간에 죽은 두 명의 사망자가 손님으로 온다. 손님을 맞이하는 건 백발의 바텐더 데킴.\n",
      "\n",
      "“두 분께서는 지금부...\n",
      "\n",
      "5. 소드 아트 온라인 -프로그레시브- 별 없는 밤의 아리아\n",
      "   장르: SF, 애니메이션, 액션, 판타지\n",
      "   총 유사도: 0.448\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.789\n",
      "     - 줄거리 TF-IDF: 0.669\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.167\n",
      "     - 장르: 0.191\n",
      "   키워드: ['이별', '고독', '게임', '아스', '죽음', '그날', '기어']\n",
      "   줄거리: 그날, '너브기어' 를 우연히 머리에 쓴 '유우키 아스나' 는  원래 인터넷 게임과는 무관하게 살고 있는 중학교 3학년 소녀였다.  게임 마스터는 통보했다.  '이건 게임이지만 놀...\n",
      "\n",
      "6. 쥬만지: 새로운 세계\n",
      "   장르: 가족, 모험, 액션, 코미디, 판타지\n",
      "   총 유사도: 0.440\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.798\n",
      "     - 줄거리 TF-IDF: 0.682\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.170\n",
      "     - 장르: 0.123\n",
      "   키워드: ['미션', '학교', '게임', '창고', '청소', '쥬만지', '비디오']\n",
      "   줄거리: 학교 창고를 청소하다가 낡은 ‘쥬만지’ 비디오 게임을 발견한 네 명의 아이들. 게임 버튼을 누르는 순간 화면 속으로 빨려 들어가버렸다! 거대한 몸집의 고고학자 닥터 브레이브스톤(드...\n",
      "\n",
      "7. 이세계 묵시록 마이노그라~파멸의 문명에서 시작하는 세계 정복~\n",
      "   장르: SF&판타지, 드라마, 애니메이션, 액션&모험\n",
      "   총 유사도: 0.439\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.806\n",
      "     - 줄거리 TF-IDF: 0.506\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.202\n",
      "     - 장르: 0.361\n",
      "   키워드: ['타쿠토', '국가', '게임', '판타지', '시뮬레이션']\n",
      "   줄거리: 판타지 세계를 무대로 한 국가 운영 시뮬레이션 게임 'Eternal Nations'.\n",
      "\n",
      "유저 랭킹 1위를 달성한 전설의 플레이어 이라 타쿠토는, 입원 중에 의식을 잃고 말았다.\n",
      "\n",
      "...\n",
      "\n",
      "8. 3D 그녀 리얼 걸\n",
      "   장르: 드라마, 애니메이션, 코미디\n",
      "   총 유사도: 0.436\n",
      "   세부 유사도:\n",
      "     - KoBERT: 0.783\n",
      "     - 줄거리 TF-IDF: 0.502\n",
      "     - 제목: 0.000\n",
      "     - 키워드: 0.356\n",
      "     - 장르: 0.220\n",
      "   키워드: ['이로하', '츠츠이', '히카리', '오타쿠', '소년']\n",
      "   줄거리: 고3 츠츠이 히카리는 말 그대로 오타쿠 소년. 게임, 만화 등의 2차원 여자아이가 있다면 혼자서도 살 수 있다 생각해왔다... 그러나 초절 3D 미소녀 이가라시 이로하에게 급고백을...\n"
     ]
    }
   ],
   "source": [
    "# 실행 예시\n",
    "if __name__ == \"__main__\":\n",
    "    # 확장된 샘플 데이터 생성\n",
    "    movies_df = pd.read_csv('../data_processing/content_data.csv', encoding='utf-8-sig')\n",
    "    \n",
    "    # 개선된 추천 시스템 초기화\n",
    "    recommender = ImprovedMovieRecommendationSystem(cache_dir=\"./cached_features\")\n",
    "    \n",
    "    # 데이터 전처리\n",
    "    recommender.prepare_data(movies_df)\n",
    "    \n",
    "    # 적응적 가중치로 추천\n",
    "    print(\"=== 어바웃 타임 기반 추천 (적응적 가중치) ===\")\n",
    "    recommendations1 = recommender.recommend_movies(\n",
    "        movie_title='유희왕 듀얼몬스터즈',\n",
    "        top_n=8,\n",
    "        use_adaptive_weights=True\n",
    "    )\n",
    "    recommender.display_recommendations(recommendations1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64ea4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kobert_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
